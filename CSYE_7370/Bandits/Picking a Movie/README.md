This notebook will talk about the Multi Armed Bandit Problem.

The notebook contains:
1. Thompson Sampling
2. Epsilon Greedy
3. Upper Confidence Bound
4. Random Sampling

It also talks about different changes in the environments and how it affects the algorithms.


Multi Armed Bandit Problem is set in the premise that there is a gambler in a casino with some number of slot machines(a bandit) and the goal is to maximize the profits by playing the machines.

Here, the need for the problem arises that the gambler does not already know the most profitable slot machine, it wouldn't be a gamble if they already did! How would the gambler know which machine to play and for how many times, for him/her to achieve maximum reward?

