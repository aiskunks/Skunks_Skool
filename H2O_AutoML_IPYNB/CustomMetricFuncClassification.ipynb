{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Custom Metric Function In Binary Classification\n",
    "\n",
    "In this notebook, we will show an example of how to calculate custom performance metrics on an H2O model for binary classification. The notebook will go through the following steps:\n",
    "\n",
    "1. Train a GBM model in H2O\n",
    "2. Write a script to calculate a weighted false negative loss\n",
    "3. Train a GBM model in H2O using this loss function as a [`custom_metric_func`](https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/dev/custom_functions.md)\n",
    "4. Train a Grid of GBMs and choose model based on this loss function\n",
    "\n",
    "\n",
    "## 1. Train a  GBM Model in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_181\"; Java(TM) SE Runtime Environment (build 1.8.0_181-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmp1vof4pgy\n",
      "  JVM stdout: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmp1vof4pgy/h2o_patrickaboyoun_started_from_python.out\n",
      "  JVM stderr: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmp1vof4pgy/h2o_patrickaboyoun_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>15 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_patrickaboyoun_7sdyyd</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.7\n",
       "H2O cluster version age:    15 days\n",
       "H2O cluster name:           H2O_from_python_patrickaboyoun_7sdyyd\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load H2O library\n",
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "train_path = \"https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv\"\n",
    "train = h2o.import_file(train_path, destination_frame = \"loan_train\")\n",
    "train[\"bad_loan\"] = train[\"bad_loan\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and predictor variables\n",
    "y = \"bad_loan\"\n",
    "x = train.col_names\n",
    "x.remove(y)\n",
    "x.remove(\"int_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train GBM Model\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "gbm_v1 = H2OGradientBoostingEstimator(model_id = \"gbm_v1.hex\")\n",
    "\n",
    "gbm_v1.train(y = y, x = x, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_v1.hex\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1363951465191071\n",
      "RMSE: 0.3693171354257843\n",
      "LogLoss: 0.43467809200204266\n",
      "Mean Per-Class Error: 0.3508577460272526\n",
      "AUC: 0.7079429892082825\n",
      "Gini: 0.41588597841656494\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19860658480443358: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>95113.0</td>\n",
       "<td>38858.0</td>\n",
       "<td>0.29</td>\n",
       "<td> (38858.0/133971.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>12401.0</td>\n",
       "<td>17615.0</td>\n",
       "<td>0.4131</td>\n",
       "<td> (12401.0/30016.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>107514.0</td>\n",
       "<td>56473.0</td>\n",
       "<td>0.3126</td>\n",
       "<td> (51259.0/163987.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      95113   38858  0.29     (38858.0/133971.0)\n",
       "1      12401   17615  0.4131   (12401.0/30016.0)\n",
       "Total  107514  56473  0.3126   (51259.0/163987.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1986066</td>\n",
       "<td>0.4073350</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1265125</td>\n",
       "<td>0.5633597</td>\n",
       "<td>311.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2803267</td>\n",
       "<td>0.3837915</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4292597</td>\n",
       "<td>0.8203272</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0438524</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2251476</td>\n",
       "<td>0.2462816</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1823683</td>\n",
       "<td>0.6488206</td>\n",
       "<td>245.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1920415</td>\n",
       "<td>0.6491423</td>\n",
       "<td>235.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.198607     0.407335  228\n",
       "max f2                       0.126512     0.56336   311\n",
       "max f0point5                 0.280327     0.383791  152\n",
       "max accuracy                 0.42926      0.820327  62\n",
       "max precision                0.777052     1         0\n",
       "max recall                   0.0438524    1         396\n",
       "max specificity              0.777052     1         0\n",
       "max absolute_mcc             0.225148     0.246282  202\n",
       "max min_per_class_accuracy   0.182368     0.648821  245\n",
       "max mean_per_class_accuracy  0.192041     0.649142  235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 18.30 %, avg score: 18.31 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100008</td>\n",
       "<td>0.4806708</td>\n",
       "<td>3.5211761</td>\n",
       "<td>3.5211761</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.0352146</td>\n",
       "<td>0.0352146</td>\n",
       "<td>252.1176084</td>\n",
       "<td>252.1176084</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200016</td>\n",
       "<td>0.4375856</td>\n",
       "<td>2.8082795</td>\n",
       "<td>3.1647278</td>\n",
       "<td>0.5140244</td>\n",
       "<td>0.4573837</td>\n",
       "<td>0.5792683</td>\n",
       "<td>0.4938727</td>\n",
       "<td>0.0280850</td>\n",
       "<td>0.0632996</td>\n",
       "<td>180.8279507</td>\n",
       "<td>216.4727796</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300024</td>\n",
       "<td>0.4110619</td>\n",
       "<td>2.6750278</td>\n",
       "<td>3.0014945</td>\n",
       "<td>0.4896341</td>\n",
       "<td>0.4234982</td>\n",
       "<td>0.5493902</td>\n",
       "<td>0.4704145</td>\n",
       "<td>0.0267524</td>\n",
       "<td>0.0900520</td>\n",
       "<td>167.5027810</td>\n",
       "<td>200.1494467</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400032</td>\n",
       "<td>0.3902679</td>\n",
       "<td>2.5117945</td>\n",
       "<td>2.8790695</td>\n",
       "<td>0.4597561</td>\n",
       "<td>0.4001474</td>\n",
       "<td>0.5269817</td>\n",
       "<td>0.4528477</td>\n",
       "<td>0.0251199</td>\n",
       "<td>0.1151719</td>\n",
       "<td>151.1794482</td>\n",
       "<td>187.9069471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500040</td>\n",
       "<td>0.3731066</td>\n",
       "<td>2.3019231</td>\n",
       "<td>2.7636402</td>\n",
       "<td>0.4213415</td>\n",
       "<td>0.3814565</td>\n",
       "<td>0.5058537</td>\n",
       "<td>0.4385695</td>\n",
       "<td>0.0230211</td>\n",
       "<td>0.1381930</td>\n",
       "<td>130.1923060</td>\n",
       "<td>176.3640189</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000018</td>\n",
       "<td>0.3147513</td>\n",
       "<td>2.0763146</td>\n",
       "<td>2.4199984</td>\n",
       "<td>0.3800463</td>\n",
       "<td>0.3412588</td>\n",
       "<td>0.4429538</td>\n",
       "<td>0.3899171</td>\n",
       "<td>0.1038113</td>\n",
       "<td>0.2420043</td>\n",
       "<td>107.6314643</td>\n",
       "<td>141.9998372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499997</td>\n",
       "<td>0.2770929</td>\n",
       "<td>1.7224882</td>\n",
       "<td>2.1875044</td>\n",
       "<td>0.3152824</td>\n",
       "<td>0.2946252</td>\n",
       "<td>0.4003984</td>\n",
       "<td>0.3581544</td>\n",
       "<td>0.0861207</td>\n",
       "<td>0.328125</td>\n",
       "<td>72.2488239</td>\n",
       "<td>118.7504446</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000037</td>\n",
       "<td>0.2503682</td>\n",
       "<td>1.5570461</td>\n",
       "<td>2.0298802</td>\n",
       "<td>0.285</td>\n",
       "<td>0.2631637</td>\n",
       "<td>0.3715470</td>\n",
       "<td>0.3344053</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.4059835</td>\n",
       "<td>55.7046075</td>\n",
       "<td>102.9880242</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999994</td>\n",
       "<td>0.2116632</td>\n",
       "<td>1.2990293</td>\n",
       "<td>1.7862732</td>\n",
       "<td>0.2377729</td>\n",
       "<td>0.2298703</td>\n",
       "<td>0.3269575</td>\n",
       "<td>0.2995617</td>\n",
       "<td>0.1298974</td>\n",
       "<td>0.5358809</td>\n",
       "<td>29.9029331</td>\n",
       "<td>78.6273176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000012</td>\n",
       "<td>0.1833189</td>\n",
       "<td>1.0747405</td>\n",
       "<td>1.6083873</td>\n",
       "<td>0.1967193</td>\n",
       "<td>0.1968137</td>\n",
       "<td>0.2943974</td>\n",
       "<td>0.2738743</td>\n",
       "<td>0.1074760</td>\n",
       "<td>0.6433569</td>\n",
       "<td>7.4740466</td>\n",
       "<td>60.8387287</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000030</td>\n",
       "<td>0.1606487</td>\n",
       "<td>0.9334851</td>\n",
       "<td>1.4734052</td>\n",
       "<td>0.1708641</td>\n",
       "<td>0.1716489</td>\n",
       "<td>0.2696905</td>\n",
       "<td>0.2534290</td>\n",
       "<td>0.0933502</td>\n",
       "<td>0.7367071</td>\n",
       "<td>-6.6514945</td>\n",
       "<td>47.3405194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999988</td>\n",
       "<td>0.1407404</td>\n",
       "<td>0.7786180</td>\n",
       "<td>1.3576120</td>\n",
       "<td>0.1425174</td>\n",
       "<td>0.1504536</td>\n",
       "<td>0.2484958</td>\n",
       "<td>0.2362671</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.8145656</td>\n",
       "<td>-22.1382009</td>\n",
       "<td>35.7612035</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000006</td>\n",
       "<td>0.1230032</td>\n",
       "<td>0.6626345</td>\n",
       "<td>1.2583278</td>\n",
       "<td>0.1212879</td>\n",
       "<td>0.1318218</td>\n",
       "<td>0.2303229</td>\n",
       "<td>0.2213461</td>\n",
       "<td>0.0662647</td>\n",
       "<td>0.8808302</td>\n",
       "<td>-33.7365534</td>\n",
       "<td>25.8327795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999963</td>\n",
       "<td>0.1056462</td>\n",
       "<td>0.5434001</td>\n",
       "<td>1.1689652</td>\n",
       "<td>0.0994633</td>\n",
       "<td>0.1142765</td>\n",
       "<td>0.2139661</td>\n",
       "<td>0.2079629</td>\n",
       "<td>0.0543377</td>\n",
       "<td>0.9351679</td>\n",
       "<td>-45.6599939</td>\n",
       "<td>16.8965234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999982</td>\n",
       "<td>0.0862040</td>\n",
       "<td>0.4147712</td>\n",
       "<td>1.0851642</td>\n",
       "<td>0.0759193</td>\n",
       "<td>0.0963432</td>\n",
       "<td>0.1986273</td>\n",
       "<td>0.1955604</td>\n",
       "<td>0.0414779</td>\n",
       "<td>0.9766458</td>\n",
       "<td>-58.5228803</td>\n",
       "<td>8.5164193</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0315070</td>\n",
       "<td>0.2335378</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0427465</td>\n",
       "<td>0.0711412</td>\n",
       "<td>0.1830389</td>\n",
       "<td>0.1831183</td>\n",
       "<td>0.0233542</td>\n",
       "<td>1.0</td>\n",
       "<td>-76.6462161</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100008                   0.480671           3.52118   3.52118            0.644512         0.530362   0.644512                    0.530362            0.0352146       0.0352146                  252.118   252.118\n",
       "    2        0.0200016                   0.437586           2.80828   3.16473            0.514024         0.457384   0.579268                    0.493873            0.028085        0.0632996                  180.828   216.473\n",
       "    3        0.0300024                   0.411062           2.67503   3.00149            0.489634         0.423498   0.54939                     0.470414            0.0267524       0.090052                   167.503   200.149\n",
       "    4        0.0400032                   0.390268           2.51179   2.87907            0.459756         0.400147   0.526982                    0.452848            0.0251199       0.115172                   151.179   187.907\n",
       "    5        0.050004                    0.373107           2.30192   2.76364            0.421341         0.381456   0.505854                    0.438569            0.0230211       0.138193                   130.192   176.364\n",
       "    6        0.100002                    0.314751           2.07631   2.42               0.380046         0.341259   0.442954                    0.389917            0.103811        0.242004                   107.631   142\n",
       "    7        0.15                        0.277093           1.72249   2.1875             0.315282         0.294625   0.400398                    0.358154            0.0861207       0.328125                   72.2488   118.75\n",
       "    8        0.200004                    0.250368           1.55705   2.02988            0.285            0.263164   0.371547                    0.334405            0.0778585       0.405983                   55.7046   102.988\n",
       "    9        0.299999                    0.211663           1.29903   1.78627            0.237773         0.22987    0.326957                    0.299562            0.129897        0.535881                   29.9029   78.6273\n",
       "    10       0.400001                    0.183319           1.07474   1.60839            0.196719         0.196814   0.294397                    0.273874            0.107476        0.643357                   7.47405   60.8387\n",
       "    11       0.500003                    0.160649           0.933485  1.47341            0.170864         0.171649   0.26969                     0.253429            0.0933502       0.736707                   -6.65149  47.3405\n",
       "    12       0.599999                    0.14074            0.778618  1.35761            0.142517         0.150454   0.248496                    0.236267            0.0778585       0.814566                   -22.1382  35.7612\n",
       "    13       0.700001                    0.123003           0.662634  1.25833            0.121288         0.131822   0.230323                    0.221346            0.0662647       0.88083                    -33.7366  25.8328\n",
       "    14       0.799996                    0.105646           0.5434    1.16897            0.0994633        0.114276   0.213966                    0.207963            0.0543377       0.935168                   -45.66    16.8965\n",
       "    15       0.899998                    0.086204           0.414771  1.08516            0.0759193        0.0963432  0.198627                    0.19556             0.0414779       0.976646                   -58.5229  8.51642\n",
       "    16       1                           0.031507           0.233538  1                  0.0427465        0.0711412  0.183039                    0.183118            0.0233542       1                          -76.6462  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:25</td>\n",
       "<td> 0.025 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3866984</td>\n",
       "<td>0.4759704</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8169611</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:26</td>\n",
       "<td> 0.755 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3847635</td>\n",
       "<td>0.4710759</td>\n",
       "<td>0.6582899</td>\n",
       "<td>2.5923891</td>\n",
       "<td>0.3376304</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:26</td>\n",
       "<td> 1.005 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3831611</td>\n",
       "<td>0.4671624</td>\n",
       "<td>0.6641427</td>\n",
       "<td>2.7218454</td>\n",
       "<td>0.3575466</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:26</td>\n",
       "<td> 1.149 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3818189</td>\n",
       "<td>0.4639557</td>\n",
       "<td>0.6658226</td>\n",
       "<td>2.8447858</td>\n",
       "<td>0.3506497</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:26</td>\n",
       "<td> 1.263 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.3806812</td>\n",
       "<td>0.4612690</td>\n",
       "<td>0.6685973</td>\n",
       "<td>2.9280752</td>\n",
       "<td>0.3523572</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:29</td>\n",
       "<td> 3.777 sec</td>\n",
       "<td>30.0</td>\n",
       "<td>0.3714227</td>\n",
       "<td>0.4396077</td>\n",
       "<td>0.6983760</td>\n",
       "<td>3.3546115</td>\n",
       "<td>0.3202998</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:29</td>\n",
       "<td> 3.876 sec</td>\n",
       "<td>31.0</td>\n",
       "<td>0.3712694</td>\n",
       "<td>0.4392390</td>\n",
       "<td>0.6990511</td>\n",
       "<td>3.3512802</td>\n",
       "<td>0.3205010</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:29</td>\n",
       "<td> 3.955 sec</td>\n",
       "<td>32.0</td>\n",
       "<td>0.3711742</td>\n",
       "<td>0.4390186</td>\n",
       "<td>0.6993193</td>\n",
       "<td>3.3446176</td>\n",
       "<td>0.3253916</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:29</td>\n",
       "<td> 4.037 sec</td>\n",
       "<td>33.0</td>\n",
       "<td>0.3710546</td>\n",
       "<td>0.4387230</td>\n",
       "<td>0.6999852</td>\n",
       "<td>3.3679366</td>\n",
       "<td>0.3274345</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-16 12:47:29</td>\n",
       "<td> 4.752 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.3693171</td>\n",
       "<td>0.4346781</td>\n",
       "<td>0.7079430</td>\n",
       "<td>3.5211761</td>\n",
       "<td>0.3125797</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse        training_logloss     training_auc        training_lift       training_classification_error\n",
       "---  -------------------  ----------  -----------------  -------------------  -------------------  ------------------  ------------------  -------------------------------\n",
       "     2018-09-16 12:47:25  0.025 sec   0.0                0.38669841055044796  0.47597036694054895  0.5                 1.0                 0.8169611005750456\n",
       "     2018-09-16 12:47:26  0.755 sec   1.0                0.38476349951235084  0.47107592549311367  0.6582898745388903  2.5923891128070995  0.3376304219236891\n",
       "     2018-09-16 12:47:26  1.005 sec   2.0                0.38316113906448107  0.46716242057962576  0.6641426875319133  2.721845434929714   0.3575466347942215\n",
       "     2018-09-16 12:47:26  1.149 sec   3.0                0.3818189070427441   0.4639557431600399   0.6658225759900159  2.8447857650909363  0.350649746626257\n",
       "     2018-09-16 12:47:26  1.263 sec   4.0                0.38068117430570636  0.46126898984825854  0.6685973490563364  2.9280751977595836  0.3523571990462659\n",
       "---  ---                  ---         ---                ---                  ---                  ---                 ---                 ---\n",
       "     2018-09-16 12:47:29  3.777 sec   30.0               0.37142274643828743  0.43960767804602063  0.6983759787436653  3.3546114633171253  0.3202997798605987\n",
       "     2018-09-16 12:47:29  3.876 sec   31.0               0.37126939711349255  0.4392390314173282   0.6990510860139607  3.351280170900723   0.32050101532438546\n",
       "     2018-09-16 12:47:29  3.955 sec   32.0               0.3711742029010424   0.4390186098656179   0.6993193041519074  3.344617586067918   0.32539164689883954\n",
       "     2018-09-16 12:47:29  4.037 sec   33.0               0.3710545566293126   0.43872301004687597  0.6999851879760314  3.3679366329827345  0.32743449175849304\n",
       "     2018-09-16 12:47:29  4.752 sec   50.0               0.3693171354257843   0.43467809200204266  0.7079429892082825  3.521176084137241   0.3125796557044156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>term</td>\n",
       "<td>2747.9863281</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2493995</td></tr>\n",
       "<tr><td>annual_inc</td>\n",
       "<td>1938.3043213</td>\n",
       "<td>0.7053544</td>\n",
       "<td>0.1759151</td></tr>\n",
       "<tr><td>addr_state</td>\n",
       "<td>1546.3793945</td>\n",
       "<td>0.5627318</td>\n",
       "<td>0.1403451</td></tr>\n",
       "<tr><td>revol_util</td>\n",
       "<td>1427.8056641</td>\n",
       "<td>0.5195825</td>\n",
       "<td>0.1295836</td></tr>\n",
       "<tr><td>purpose</td>\n",
       "<td>934.7630005</td>\n",
       "<td>0.3401629</td>\n",
       "<td>0.0848365</td></tr>\n",
       "<tr><td>dti</td>\n",
       "<td>847.0342407</td>\n",
       "<td>0.3082382</td>\n",
       "<td>0.0768744</td></tr>\n",
       "<tr><td>loan_amnt</td>\n",
       "<td>627.7856445</td>\n",
       "<td>0.2284530</td>\n",
       "<td>0.0569761</td></tr>\n",
       "<tr><td>emp_length</td>\n",
       "<td>249.1807861</td>\n",
       "<td>0.0906776</td>\n",
       "<td>0.0226149</td></tr>\n",
       "<tr><td>home_ownership</td>\n",
       "<td>239.7884827</td>\n",
       "<td>0.0872597</td>\n",
       "<td>0.0217625</td></tr>\n",
       "<tr><td>total_acc</td>\n",
       "<td>163.4083862</td>\n",
       "<td>0.0594648</td>\n",
       "<td>0.0148305</td></tr>\n",
       "<tr><td>delinq_2yrs</td>\n",
       "<td>128.5801697</td>\n",
       "<td>0.0467907</td>\n",
       "<td>0.0116696</td></tr>\n",
       "<tr><td>longest_credit_length</td>\n",
       "<td>117.2748566</td>\n",
       "<td>0.0426767</td>\n",
       "<td>0.0106435</td></tr>\n",
       "<tr><td>verification_status</td>\n",
       "<td>50.1193047</td>\n",
       "<td>0.0182386</td>\n",
       "<td>0.0045487</td></tr></table></div>"
      ],
      "text/plain": [
       "variable               relative_importance    scaled_importance    percentage\n",
       "---------------------  ---------------------  -------------------  ------------\n",
       "term                   2747.99                1                    0.2494\n",
       "annual_inc             1938.3                 0.705354             0.175915\n",
       "addr_state             1546.38                0.562732             0.140345\n",
       "revol_util             1427.81                0.519583             0.129584\n",
       "purpose                934.763                0.340163             0.0848365\n",
       "dti                    847.034                0.308238             0.0768744\n",
       "loan_amnt              627.786                0.228453             0.0569761\n",
       "emp_length             249.181                0.0906776            0.0226149\n",
       "home_ownership         239.788                0.0872597            0.0217625\n",
       "total_acc              163.408                0.0594648            0.0148305\n",
       "delinq_2yrs            128.58                 0.0467907            0.0116696\n",
       "longest_credit_length  117.275                0.0426767            0.0106435\n",
       "verification_status    50.1193                0.0182386            0.00454869"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(gbm_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write Script to Calculate Weighted False Negative Loss\n",
    "\n",
    "### Function to Calculate Normalized Cost Matrix Loss in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizedCostMatrixLoss(actual, predicted, cost_tp, cost_tn, cost_fp, cost_fn):\n",
    "    c1 = cost_tp + cost_tn - cost_fp - cost_fn\n",
    "    c2 = cost_fn - cost_tn\n",
    "    c3 = cost_fp - cost_tn\n",
    "    c4 = cost_tn\n",
    "\n",
    "    num = (actual * predicted * c1) + (actual * c2) + (predicted * c3) + c4\n",
    "    denom = actual.ifelse(cost_fn, cost_fp)\n",
    "    cost = num.sum() / denom.sum()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"weight\"] = train[\"loan_amnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "NormalizedCostMatrixLoss: 0.4239\n"
     ]
    }
   ],
   "source": [
    "loss_v1 = NormalizedCostMatrixLoss(train[y].asnumeric(), gbm_v1.predict(train)[\"p1\"], 5000, 0, 5000, train[\"weight\"])\n",
    "print(\"NormalizedCostMatrixLoss: \" + str(round(loss_v1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script to calculate Weighted False Negative Loss in custom_metric_func\n",
    "\n",
    "The weighted false negative loss metric is defined in a class stored in utils_model_metrics.py. This class contains three methods `map`, `reduce`, and `metric`. The `map` method takes 5 arguments `predicted`, `actual`, `weight`, `offset` and `model`.\n",
    "\n",
    "```\n",
    "class WeightedFalseNegativeLossMetric:\n",
    "    def map(self, predicted, actual, weight, offset, model):\n",
    "        cost_tp = 5000 # set prior to use\n",
    "        cost_tn = 0 # do not change\n",
    "        cost_fp = cost_tp # do not change\n",
    "        cost_fn = weight # do not change\n",
    "\n",
    "        # c1 = cost_tp + cost_tn - cost_fp - cost_fn\n",
    "        # c2 = cost_fn - cost_tn\n",
    "        # c3 = cost_fp - cost_tn\n",
    "        # c4 = cost_tn\n",
    "        # (y * p * c1) + (y * c2) + (p * c3) + c4\n",
    "\n",
    "        y = actual[0]\n",
    "        p = predicted[2] # [class, p0, p1]\n",
    "        if y == 1:\n",
    "            denom = cost_fn\n",
    "        else:\n",
    "            denom = cost_fp\n",
    "        return [(y * (1 - p) * cost_fn) + (p * cost_fp), denom]\n",
    "\n",
    "    def reduce(self, left, right):\n",
    "        return [left[0] + right[0], left[1] + right[1]]\n",
    "\n",
    "    def metric(self, last):\n",
    "        return last[0] / last[1]\n",
    "```\n",
    "\n",
    "This class definition is uploaded to the H2O cluster using [`h2o.upload_custom_metric`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html?highlight=custom_metric#h2o.upload_custom_metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model_metrics import WeightedFalseNegativeLossMetric\n",
    "\n",
    "weighted_false_negative_loss_func = h2o.upload_custom_metric(WeightedFalseNegativeLossMetric,\n",
    "                                                 func_name = \"WeightedFalseNegativeLoss\",\n",
    "                                                 func_file = \"weighted_false_negative_loss.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weighted_false_negative_loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:WeightedFalseNegativeLoss=weighted_false_negative_loss.WeightedFalseNegativeLossMetricWrapper\n"
     ]
    }
   ],
   "source": [
    "print(weighted_false_negative_loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a GBM Model using custom_metric_func\n",
    "\n",
    "The [`H2OGeneralizedLinearEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2ogeneralizedlinearestimator),\n",
    "[`H2ORandomForestEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2orandomforestestimator), and\n",
    "[`H2OGradientBoostingEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2ogradientboostingestimator) models accept a `custom_metric_func` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train GBM Model with custom_metric_function\n",
    "gbm_v2 = H2OGradientBoostingEstimator(model_id = \"gbm_v2.hex\",\n",
    "                                      custom_metric_func = weighted_false_negative_loss_func)\n",
    "\n",
    "gbm_v2.train(y = y, x = x, training_frame = train, weights_column = \"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.14194205086753872\n",
      "RMSE: 0.376751975266937\n",
      "LogLoss: 0.44785973758467373\n",
      "Mean Per-Class Error: 0.340920265265635\n",
      "AUC: 0.7186517880386486\n",
      "Gini: 0.4373035760772972\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2208251278711907: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>1256403850.0000000</td>\n",
       "<td>465408000.0000000</td>\n",
       "<td>0.2703</td>\n",
       "<td> (465408000.0/1721811850.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>175106300.0000000</td>\n",
       "<td>247075625.0000000</td>\n",
       "<td>0.4148</td>\n",
       "<td> (175106300.0/422181925.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1431510150.0000000</td>\n",
       "<td>712483625.0000000</td>\n",
       "<td>0.2987</td>\n",
       "<td> (640514300.0/2143993775.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0            1            Error    Rate\n",
       "-----  -----------  -----------  -------  --------------------------\n",
       "0      1.2564e+09   4.65408e+08  0.2703   (465408000.0/1721811850.0)\n",
       "1      1.75106e+08  2.47076e+08  0.4148   (175106300.0/422181925.0)\n",
       "Total  1.43151e+09  7.12484e+08  0.2987   (640514300.0/2143993775.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2208251</td>\n",
       "<td>0.4355039</td>\n",
       "<td>225.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1338078</td>\n",
       "<td>0.5862034</td>\n",
       "<td>314.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3111775</td>\n",
       "<td>0.4160830</td>\n",
       "<td>149.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4219306</td>\n",
       "<td>0.8100069</td>\n",
       "<td>81.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8482319</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0456742</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8482319</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2527278</td>\n",
       "<td>0.2696590</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1981595</td>\n",
       "<td>0.6573922</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2070156</td>\n",
       "<td>0.6590797</td>\n",
       "<td>238.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.220825     0.435504  225\n",
       "max f2                       0.133808     0.586203  314\n",
       "max f0point5                 0.311177     0.416083  149\n",
       "max accuracy                 0.421931     0.810007  81\n",
       "max precision                0.848232     1         0\n",
       "max recall                   0.0456742    1         398\n",
       "max specificity              0.848232     1         0\n",
       "max absolute_mcc             0.252728     0.269659  196\n",
       "max min_per_class_accuracy   0.198159     0.657392  246\n",
       "max mean_per_class_accuracy  0.207016     0.65908   238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.69 %, avg score: 19.70 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100040</td>\n",
       "<td>0.4989871</td>\n",
       "<td>3.6195299</td>\n",
       "<td>3.6195299</td>\n",
       "<td>0.7127353</td>\n",
       "<td>0.5558560</td>\n",
       "<td>0.7127353</td>\n",
       "<td>0.5558560</td>\n",
       "<td>0.0362099</td>\n",
       "<td>0.0362099</td>\n",
       "<td>261.9529924</td>\n",
       "<td>261.9529924</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200064</td>\n",
       "<td>0.4620542</td>\n",
       "<td>3.0621888</td>\n",
       "<td>3.3408834</td>\n",
       "<td>0.6029872</td>\n",
       "<td>0.4785761</td>\n",
       "<td>0.6578660</td>\n",
       "<td>0.5172193</td>\n",
       "<td>0.0306290</td>\n",
       "<td>0.0668389</td>\n",
       "<td>206.2188848</td>\n",
       "<td>234.0883424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300004</td>\n",
       "<td>0.4366559</td>\n",
       "<td>2.6700122</td>\n",
       "<td>3.1173954</td>\n",
       "<td>0.5257622</td>\n",
       "<td>0.4486896</td>\n",
       "<td>0.6138581</td>\n",
       "<td>0.4943900</td>\n",
       "<td>0.0266843</td>\n",
       "<td>0.0935232</td>\n",
       "<td>167.0012195</td>\n",
       "<td>211.7395446</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400071</td>\n",
       "<td>0.4169808</td>\n",
       "<td>2.4709308</td>\n",
       "<td>2.9557003</td>\n",
       "<td>0.4865603</td>\n",
       "<td>0.4265782</td>\n",
       "<td>0.5820181</td>\n",
       "<td>0.4774287</td>\n",
       "<td>0.0247258</td>\n",
       "<td>0.1182490</td>\n",
       "<td>147.0930841</td>\n",
       "<td>195.5700253</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500068</td>\n",
       "<td>0.4020904</td>\n",
       "<td>2.2519128</td>\n",
       "<td>2.8149662</td>\n",
       "<td>0.4434327</td>\n",
       "<td>0.4091541</td>\n",
       "<td>0.5543056</td>\n",
       "<td>0.4637761</td>\n",
       "<td>0.0225184</td>\n",
       "<td>0.1407674</td>\n",
       "<td>125.1912818</td>\n",
       "<td>181.4966201</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000023</td>\n",
       "<td>0.3450399</td>\n",
       "<td>2.1048786</td>\n",
       "<td>2.4599624</td>\n",
       "<td>0.4144796</td>\n",
       "<td>0.3710892</td>\n",
       "<td>0.4844005</td>\n",
       "<td>0.4174379</td>\n",
       "<td>0.1052345</td>\n",
       "<td>0.2460019</td>\n",
       "<td>110.4878588</td>\n",
       "<td>145.9962386</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500058</td>\n",
       "<td>0.3063922</td>\n",
       "<td>1.8004637</td>\n",
       "<td>2.2401226</td>\n",
       "<td>0.3545361</td>\n",
       "<td>0.3246164</td>\n",
       "<td>0.4411110</td>\n",
       "<td>0.3864964</td>\n",
       "<td>0.0900295</td>\n",
       "<td>0.3360314</td>\n",
       "<td>80.0463721</td>\n",
       "<td>124.0122594</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000091</td>\n",
       "<td>0.2763789</td>\n",
       "<td>1.5714338</td>\n",
       "<td>2.0729470</td>\n",
       "<td>0.3094370</td>\n",
       "<td>0.2909867</td>\n",
       "<td>0.4081918</td>\n",
       "<td>0.3626185</td>\n",
       "<td>0.0785768</td>\n",
       "<td>0.4146082</td>\n",
       "<td>57.1433818</td>\n",
       "<td>107.2947018</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000010</td>\n",
       "<td>0.2319078</td>\n",
       "<td>1.3303017</td>\n",
       "<td>1.8254195</td>\n",
       "<td>0.2619547</td>\n",
       "<td>0.2531673</td>\n",
       "<td>0.3594503</td>\n",
       "<td>0.3261378</td>\n",
       "<td>0.1330194</td>\n",
       "<td>0.5476276</td>\n",
       "<td>33.0301710</td>\n",
       "<td>82.5419471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000033</td>\n",
       "<td>0.1982979</td>\n",
       "<td>1.0737695</td>\n",
       "<td>1.6375041</td>\n",
       "<td>0.2114400</td>\n",
       "<td>0.2144108</td>\n",
       "<td>0.3224471</td>\n",
       "<td>0.2982056</td>\n",
       "<td>0.1073795</td>\n",
       "<td>0.6550071</td>\n",
       "<td>7.3769507</td>\n",
       "<td>63.7504115</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000036</td>\n",
       "<td>0.1710281</td>\n",
       "<td>0.8975324</td>\n",
       "<td>1.4895104</td>\n",
       "<td>0.1767365</td>\n",
       "<td>0.1842133</td>\n",
       "<td>0.2933051</td>\n",
       "<td>0.2754073</td>\n",
       "<td>0.0897535</td>\n",
       "<td>0.7447606</td>\n",
       "<td>-10.2467629</td>\n",
       "<td>48.9510418</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000016</td>\n",
       "<td>0.1481248</td>\n",
       "<td>0.7663103</td>\n",
       "<td>1.3689798</td>\n",
       "<td>0.1508971</td>\n",
       "<td>0.1592979</td>\n",
       "<td>0.2695710</td>\n",
       "<td>0.2560561</td>\n",
       "<td>0.0766295</td>\n",
       "<td>0.8213901</td>\n",
       "<td>-23.3689738</td>\n",
       "<td>36.8979750</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000036</td>\n",
       "<td>0.1286027</td>\n",
       "<td>0.6326451</td>\n",
       "<td>1.2637876</td>\n",
       "<td>0.1245765</td>\n",
       "<td>0.1381659</td>\n",
       "<td>0.2488572</td>\n",
       "<td>0.2392144</td>\n",
       "<td>0.0632657</td>\n",
       "<td>0.8846558</td>\n",
       "<td>-36.7354883</td>\n",
       "<td>26.3787590</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000025</td>\n",
       "<td>0.1104765</td>\n",
       "<td>0.5187399</td>\n",
       "<td>1.1706579</td>\n",
       "<td>0.1021470</td>\n",
       "<td>0.1194285</td>\n",
       "<td>0.2305187</td>\n",
       "<td>0.2242414</td>\n",
       "<td>0.0518734</td>\n",
       "<td>0.9365293</td>\n",
       "<td>-48.1260118</td>\n",
       "<td>17.0657918</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000010</td>\n",
       "<td>0.0905324</td>\n",
       "<td>0.4001388</td>\n",
       "<td>1.0850461</td>\n",
       "<td>0.0787928</td>\n",
       "<td>0.1009617</td>\n",
       "<td>0.2136605</td>\n",
       "<td>0.2105439</td>\n",
       "<td>0.0400133</td>\n",
       "<td>0.9765425</td>\n",
       "<td>-59.9861240</td>\n",
       "<td>8.5046088</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0384880</td>\n",
       "<td>0.2345771</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0461915</td>\n",
       "<td>0.0751048</td>\n",
       "<td>0.1969138</td>\n",
       "<td>0.1970001</td>\n",
       "<td>0.0234575</td>\n",
       "<td>1.0</td>\n",
       "<td>-76.5422932</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010004                    0.498987           3.61953   3.61953            0.712735         0.555856   0.712735                    0.555856            0.0362099       0.0362099                  261.953   261.953\n",
       "    2        0.0200064                   0.462054           3.06219   3.34088            0.602987         0.478576   0.657866                    0.517219            0.030629        0.0668389                  206.219   234.088\n",
       "    3        0.0300004                   0.436656           2.67001   3.1174             0.525762         0.44869    0.613858                    0.49439             0.0266843       0.0935232                  167.001   211.74\n",
       "    4        0.0400071                   0.416981           2.47093   2.9557             0.48656          0.426578   0.582018                    0.477429            0.0247258       0.118249                   147.093   195.57\n",
       "    5        0.0500068                   0.40209            2.25191   2.81497            0.443433         0.409154   0.554306                    0.463776            0.0225184       0.140767                   125.191   181.497\n",
       "    6        0.100002                    0.34504            2.10488   2.45996            0.41448          0.371089   0.4844                      0.417438            0.105234        0.246002                   110.488   145.996\n",
       "    7        0.150006                    0.306392           1.80046   2.24012            0.354536         0.324616   0.441111                    0.386496            0.0900295       0.336031                   80.0464   124.012\n",
       "    8        0.200009                    0.276379           1.57143   2.07295            0.309437         0.290987   0.408192                    0.362618            0.0785768       0.414608                   57.1434   107.295\n",
       "    9        0.300001                    0.231908           1.3303    1.82542            0.261955         0.253167   0.35945                     0.326138            0.133019        0.547628                   33.0302   82.5419\n",
       "    10       0.400003                    0.198298           1.07377   1.6375             0.21144          0.214411   0.322447                    0.298206            0.107379        0.655007                   7.37695   63.7504\n",
       "    11       0.500004                    0.171028           0.897532  1.48951            0.176736         0.184213   0.293305                    0.275407            0.0897535       0.744761                   -10.2468  48.951\n",
       "    12       0.600002                    0.148125           0.76631   1.36898            0.150897         0.159298   0.269571                    0.256056            0.0766295       0.82139                    -23.369   36.898\n",
       "    13       0.700004                    0.128603           0.632645  1.26379            0.124577         0.138166   0.248857                    0.239214            0.0632657       0.884656                   -36.7355  26.3788\n",
       "    14       0.800002                    0.110476           0.51874   1.17066            0.102147         0.119429   0.230519                    0.224241            0.0518734       0.936529                   -48.126   17.0658\n",
       "    15       0.900001                    0.0905324          0.400139  1.08505            0.0787928        0.100962   0.213661                    0.210544            0.0400133       0.976543                   -59.9861  8.50461\n",
       "    16       1                           0.038488           0.234577  1                  0.0461915        0.0751048  0.196914                    0.197               0.0234575       1                          -76.5423  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WeightedFalseNegativeLoss: 0.42381109064735906\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = gbm_v2.model_performance()\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedFalseNegativeLoss'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.custom_metric_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42381109064735906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.custom_metric_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that our custom weighted false negative loss function is in the model performance metrics labeled `WeightedFalseNegativeLoss`.  This value matches the value calculated in our original GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss V1: 0.4239\n",
      "Loss V2: 0.4238\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss V1: \" + str(round(loss_v1, 4)))\n",
    "print(\"Loss V2: \" + str(round(gbm_v2.model_performance().custom_metric_value(), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Grid of GBMs and choose model based on custom loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "gbm_hyper_parameters = {'max_depth': [4, 5, 6]}\n",
    "gbm_grid = H2OGridSearch(H2OGradientBoostingEstimator(custom_metric_func = weighted_false_negative_loss_func,\n",
    "                                                      nfolds = 5),\n",
    "                           gbm_hyper_parameters)\n",
    "gbm_grid.train(x = x, y = y, training_frame = train, weights_column = \"weight\", grid_id = \"gbm_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.423955824695979, 'gbm_grid_model_2'],\n",
       " [0.42850913512546235, 'gbm_grid_model_1'],\n",
       " [0.4308449289981675, 'gbm_grid_model_0']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([[h2o.get_model(x).model_performance(xval = True).custom_metric_value(), x] for x in gbm_grid.model_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown H2O Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_9b1d closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
