{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial shows how a H2O [Generalized Linear Model](https://en.wikipedia.org/wiki/Generalized_linear_model) model can be used to do supervised classification. This tutorial covers usage of H2O from Python. An R version of this tutorial will be available as well in a separate document. This file is available in plain R, plain Python and iPython Notebook formats. More examples and explanations can be found in our [H2O Generalized Linear Modeling booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Python Module\n",
    "\n",
    "Load the H2O Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O\n",
    "Start up a 1-node H2O cloud on your local machine, and allow it to use all CPU cores and up to 2GB of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.init(max_mem_size = \"2G\")             #specify max number of bytes. uses all cores by default.\n",
    "h2o.remove_all()                          #clean slate, in case cluster was already running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "help(H2OGeneralizedLinearEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use pandas DataFrames to simplify some processes later in this demo, let's import both pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##H2O GLM\n",
    "\n",
    "Generalized linear models (GLMs) are an extension of traditional linear models. They have gained popularity in statistical data analysis due to:  \n",
    "\n",
    "1. the flexibility of the model structure unifying the typical regression methods (such as linear regression and logistic regression for binary classification)  \n",
    "2. the recent availability of model-fitting software  \n",
    "3. the ability to scale well with large datasets  \n",
    "\n",
    "H2O's GLM algorithm fits generalized linear models to the data by maximizing the log-likelihood. The elastic net penalty can be used for parameter regularization. The model fitting computation is distributed, extremely fast, and scales extremely well for models with a limited number of predictors with non-zero coefficients (~ low thousands).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting started\n",
    "\n",
    "We begin by importing our data into H2OFrames, which operate similarly in function to pandas DataFrames but exist on the H2O cloud itself.  \n",
    "\n",
    "In this case, the H2O cluster is running on our laptops. Data files are imported by their relative locations to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "covtype_df = h2o.import_file(os.path.realpath(\"../data/covtype.full.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the full covertype dataset (581k rows, 13 columns, 10 numerical, 3 categorical) and then split the data 3 ways:  \n",
    "  \n",
    "60% for training  \n",
    "20% for validation (hyper parameter tuning)  \n",
    "20% for final testing  \n",
    "\n",
    " We will train a data set on one set and use the others to test the validity of the model by ensuring that it can predict accurately on data the model has not been shown.  \n",
    " \n",
    " The second set will be used for validation most of the time.  \n",
    " \n",
    " The third set will be withheld until the end, to ensure that our validation accuracy is consistent with data we have never seen during the iterative process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.7, 0.15], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = covtype_df.col_names[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The First Multinomial Model\n",
    "\n",
    "Our goal is to perform classification on cartographical data into tree cover categories.\n",
    "\n",
    "This is a multinomial problem, so let's begin by building a multinomial GLM model with default parameters!\n",
    "\n",
    "We will use the Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) algorithm to ensure that this demo can be run in almost all environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v1 = H2OGeneralizedLinearEstimator(\n",
    "                    model_id='glm_v1',            #allows us to easily locate this model in Flow\n",
    "                    family='multinomial',\n",
    "                    solver='L_BFGS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Model Construction\n",
    "H2O in Python is designed to be very similar in look and feel to to scikit-learn. Models are initialized individually with desired or default parameters and then trained on data.  \n",
    "\n",
    "**Note that the below example uses model.train() as opposed the traditional model.fit()**  \n",
    "This is because h2o-py takes column indices for the feature and response columns AND the whole data frame, while scikit-learn takes in a feature frame and a response frame.\n",
    "\n",
    "H2O supports model.fit() so that it can be incorporated into a scikit-learn pipeline, but we advise using train() in all other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view information about the model in [Flow](http://localhost:54321/) or within Python. To find more information in Flow, enter `getModel \"rf_covType_v1\"` into a cell and run in place pressing Ctrl-Enter. Alternatively, you can click on the Models tab, select List All Models, and click on the model named \"rf_covType_v1\" as specified in our model construction above.\n",
    "\n",
    "In Python, we can use call the model itself to get an overview of its stats,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out a little more about its performance, we can look at its hit ratio table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Updating our GLM Estimator\n",
    "As we can see, the k=1 hit ratio indicates that we're very far off of a good estimator. Judging by our training and validation scores, we don't seem to be overfitting. Perhaps we're over-regularizing?\n",
    "\n",
    "Let's try again with a lower lambda value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v2 = H2OGeneralizedLinearEstimator(\n",
    "                    model_id='glm_v2',           \n",
    "                    family='multinomial',\n",
    "                    solver='L_BFGS',\n",
    "                    Lambda=0.0001                 #default value 0.001\n",
    ")\n",
    "glm_multi_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a noticeable improvement in the MSE, and our hit ratio has improved from coin-flip to 72%. \n",
    "\n",
    "Let's look at the confusion matrix to see if we can gather any more insight on the errors in our multinomial classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v2.confusion_matrix(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1 & 2 Struggles\n",
    "\n",
    "As we can see in the above confusion matrix, our model is struggling to correctly distinguish between covertype classes 1 and 2. To learn more about this, let's shrink the scope of our problem to a binomial classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binomial Classification\n",
    "\n",
    "Let's only look at the rows where coverage is class_1 or class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = covtype_df[covtype_df['Cover_Type'] == 'class_1']\n",
    "c2 = covtype_df[covtype_df['Cover_Type'] == 'class_2']\n",
    "df_b = c1.rbind(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's split this into train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the data as described above\n",
    "train_b, valid_b, test_b = df_b.split_frame([0.7, 0.15], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a binomial classifier with the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_v1 = H2OGeneralizedLinearEstimator(\n",
    "                    model_id=\"glm_v3\",\n",
    "                    solver=\"L_BFGS\",\n",
    "                    family=\"binomial\")\n",
    "glm_binom_v1.train(covtype_X, covtype_y, training_frame=train_b, validation_frame=valid_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_v1.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data in its natural state does not classify particularly cleanly into class_1 or class_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Featurization\n",
    "\n",
    "Let's add some features to this binomial model to see if we can improve its predictive capacity. We'll do a combination of binning (by converting several numeric fields to categorical) and interaction variables. To do this cleanly, we use the two helper functions defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_column(train_df, train, valid, test, col):\n",
    "    '''\n",
    "    Convenience function to change a column from numerical to categorical\n",
    "    We use train_df only for bucketing with histograms.\n",
    "    Uses np.histogram to generate a histogram, with the buckets forming the categories of our new categorical.\n",
    "    Picks buckets based on training data, then applies the same classification to the test and validation sets\n",
    "    \n",
    "    Assumes that train, valid, test will have the same histogram behavior.\n",
    "    '''\n",
    "    only_col= train_df[col]                            #Isolate the column in question from the training frame\n",
    "    counts, breaks = np.histogram(only_col, bins=20)   #Generate counts and breaks for our histogram\n",
    "    min_val = min(only_col)-1                          #Establish min and max values\n",
    "    max_val = max(only_col)+1\n",
    "    \n",
    "    new_b = [min_val]                                  #Redefine breaks such that each bucket has enough support\n",
    "    for i in xrange(19):\n",
    "        if counts[i] > 1000 and counts[i+1] > 1000:\n",
    "            new_b.append(breaks[i+1])\n",
    "    new_b.append(max_val)\n",
    "    \n",
    "    names = [col + '_' + str(x) for x in xrange(len(new_b)-1)]  #Generate names for buckets, these will be categorical names\n",
    "\n",
    "    train[col+\"_cut\"] = train[col].cut(breaks=new_b, labels=names)\n",
    "    valid[col+\"_cut\"] = valid[col].cut(breaks=new_b, labels=names)\n",
    "    test[col+\"_cut\"] = test[col].cut(breaks=new_b, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(train, valid, test):\n",
    "    '''\n",
    "    Helper function to add a specific set of features to our covertype dataset\n",
    "    '''\n",
    "    #pull train dataset into Python\n",
    "    train_df = train.as_data_frame(True)\n",
    "    \n",
    "    #Make categoricals for several columns\n",
    "    cut_column(train_df, train, valid, test, \"Elevation\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_Noon\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_9am\")\n",
    "    cut_column(train_df, train, valid, test, \"Hillshade_3pm\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Hydrology\")\n",
    "    cut_column(train_df, train, valid, test, \"Slope\")\n",
    "    cut_column(train_df, train, valid, test, \"Horizontal_Distance_To_Roadways\")\n",
    "    cut_column(train_df, train, valid, test, \"Aspect\")\n",
    "    \n",
    "    \n",
    "    #Add interaction columns for a subset of columns\n",
    "    interaction_cols1 = [\"Elevation_cut\",\n",
    "                         \"Wilderness_Area\",\n",
    "                         \"Soil_Type\",\n",
    "                         \"Hillshade_Noon_cut\",\n",
    "                         \"Hillshade_9am_cut\",\n",
    "                         \"Hillshade_3pm_cut\",\n",
    "                         \"Horizontal_Distance_To_Hydrology_cut\",\n",
    "                         \"Slope_cut\",\n",
    "                         \"Horizontal_Distance_To_Roadways_cut\",\n",
    "                         \"Aspect_cut\"]\n",
    "\n",
    "    train_cols = train.interaction(factors=interaction_cols1,    #Generate pairwise columns\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itrain\")\n",
    "    valid_cols = valid.interaction(factors=interaction_cols1,\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"ivalid\")\n",
    "    test_cols = test.interaction(factors=interaction_cols1,\n",
    "                                   pairwise=True,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itest\")\n",
    "    \n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "    \n",
    "    \n",
    "    #Add a three-way interaction for Hillshade\n",
    "    interaction_cols2 = [\"Hillshade_Noon_cut\",\"Hillshade_9am_cut\",\"Hillshade_3pm_cut\"]\n",
    "    \n",
    "    train_cols = train.interaction(factors=interaction_cols2,    #Generate pairwise columns\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itrain\")\n",
    "    valid_cols = valid.interaction(factors=interaction_cols2,\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"ivalid\")\n",
    "    test_cols = test.interaction(factors=interaction_cols2,\n",
    "                                   pairwise=False,\n",
    "                                   max_factors=1000,\n",
    "                                   min_occurrence=100,\n",
    "                                   destination_frame=\"itest\")\n",
    "    \n",
    "    train = train.cbind(train_cols)                              #Append pairwise columns to H2OFrames\n",
    "    valid = valid.cbind(valid_cols)\n",
    "    test = test.cbind(test_cols)\n",
    "    \n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Add features to our binomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_bf, valid_bf, test_bf = add_features(train_b, valid_b, test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_1 = H2OGeneralizedLinearEstimator(family='binomial', solver='L_BFGS', model_id='glm_v4')\n",
    "glm_binom_feat_1.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_1.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We appear to have marginal improvement in accuracy! Inspecting in flow, we see that we may be over-regularizing like in our very first model, so we once again decrement lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_2 = H2OGeneralizedLinearEstimator(family='binomial', solver='L_BFGS', model_id='glm_v5', Lambda=0.001)\n",
    "glm_binom_feat_2.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_2.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Validation accuracy is increasing! Let's try adding in lambda search to see if we can possibly improve any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_3 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_v6', lambda_search=True)\n",
    "glm_binom_feat_3.train(covtype_X, covtype_y, training_frame=train_bf, validation_frame=valid_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_binom_feat_3.accuracy(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields minimal improvements over lambda=0.001. Thus, we can conclude that the optimal lambda value is quite close to 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Revisiting the Multinomial\n",
    "\n",
    "We've managed to reduce the error in classification between class_1 and class_2 by adding some features and categorizing others. Let's apply these changes to our original multinomial model to see what sorts of gains we can achieve. First let's featurize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_f, valid_f, test_f = add_features(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a final multinomial classifier with our featurized data and a near-optimal lambda of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v3 = H2OGeneralizedLinearEstimator(\n",
    "                    model_id='glm_v7',           \n",
    "                    family='multinomial',\n",
    "                    solver='L_BFGS',\n",
    "                    Lambda=0.0001)\n",
    "glm_multi_v3.train(covtype_X, covtype_y, training_frame=train_f, validation_frame=valid_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v3.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hit ratio has improved dramatically since our first multinomial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More information can be found in the [H2O Generalized Linear Modeling Booklet](http://h2o.ai/resources/), in our [H2O SlideShare Presentations](http://www.slideshare.net/0xdata/presentations), our [H2O YouTube channel](https://www.youtube.com/user/0xdata/), as well as on our [H2O Github Repository](https://github.com/h2oai/h2o-3/), especially in our [H2O GLM R tests](https://github.com/h2oai/h2o-3/tree/master/h2o-r/tests/testdir_algos), and [H2O GLM tests](https://github.com/h2oai/h2o-3/tree/master/h2o-py/tests/testdir_algos/glm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
