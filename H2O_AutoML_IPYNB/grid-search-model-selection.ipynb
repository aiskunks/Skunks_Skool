{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O Machine Learning Tutorial: Grid Search & Model Selection\n",
    "\n",
    "Prepared for H2O Open Chicago 2016: http://open.h2o.ai/chicago.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install H2O\n",
    "\n",
    "The first step in this tutorial is to download and install the h2o Python module.  \n",
    "The latest version is always here: http://www.h2o.ai/download/h2o/py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the H2O Cluster\n",
    "\n",
    "Once the Python module is installed, we begin by starting up a local (on your laptop) H2O cluster.  If you are already running an H2O cluster from the introductory H2O tutorial, stop the H2O cluster and restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the cluster is running already, shut down and start up a new instance\n",
    "#import h2o\n",
    "#h2o.shutdown(prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmpnn72d7/h2o_me_started_from_python.out\n",
      "JVM stderr: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmpeV2nfR/h2o_me_started_from_python.err\n",
      "Using ice_root: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmp8znRmy\n",
      "\n",
      "\n",
      "Java Version: java version \"1.8.0_45\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_45-b14)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ......... Connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 40 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_me_wzy124</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>7.11 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.10</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ---------------------------------\n",
       "H2O cluster uptime:             1 seconds 40 milliseconds\n",
       "H2O cluster version:            3.8.2.3\n",
       "H2O cluster name:               H2O_started_from_python_me_wzy124\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  7.11 GB\n",
       "H2O cluster total cores:        8\n",
       "H2O cluster allowed cores:      8\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.10\n",
       "------------------------------  ---------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the H2O library and start up the H2O cluter locally on your machine\n",
    "import h2o\n",
    "\n",
    "# Number of threads, nthreads = -1, means use all cores on your machine\n",
    "# max_mem_size is the maximum memory (in GB) to allocate to H2O\n",
    "h2o.init(nthreads = -1, max_mem_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "### Import data\n",
    "Next we will import a cleaned up version of the Lending Club \"Bad Loans\" dataset. The purpose here is to predict whether a loan will be bad (i.e. not repaid to the lender). The response column, `bad_loan`, is 1 if the loan was bad, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [                                                  ] 00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h2o/h2o.py:316: UserWarning: ParseError at file nfs://Volumes/H2OTOUR/loan.csv  at byte offset 4194304; error = 'Unmatched quote char \"'\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "loan_csv = \"/Volumes/H2OTOUR/loan.csv\"  # modify this for your machine\n",
    "# Alternatively, you can import the data directly from a URL\n",
    "#loan_csv = \"https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv\"\n",
    "data = h2o.import_file(loan_csv)  # 163,987 rows x 15 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163987, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode response variable\n",
    "Since we want to train a binary classification model, we must ensure that the response is coded as a factor. If the response is 0/1, H2O will assume it's numeric, which means that H2O will train a regression model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bad_loan'] = data['bad_loan'].asfactor()  #encode the binary repsonse as a factor\n",
    "data['bad_loan'].levels()  #optional: after encoding, this shows the two factor levels, '0' and '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition data\n",
    "\n",
    "Next, we partition the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partition data into 70%, 15%, 15% chunks\n",
    "# Setting a seed will guarantee reproducibility\n",
    "\n",
    "splits = data.split_frame(ratios=[0.7, 0.15], seed=1)  \n",
    "\n",
    "train = splits[0]\n",
    "valid = splits[1]\n",
    "test = splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `split_frame()` uses approximate splitting not exact splitting (for efficiency), so these are not exactly 70%, 15% and 15% of the total rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114908\n",
      "24498\n",
      "24581\n"
     ]
    }
   ],
   "source": [
    "print train.nrow\n",
    "print valid.nrow\n",
    "print test.nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify response and predictor variables\n",
    "In H2O, we use `y` to designate the response variable and `x` to designate the list of predictor columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 'bad_loan'\n",
    "x = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.remove(y)  #remove the response\n",
    "x.remove('int_rate')  #remove the interest rate column because it's correlated with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'loan_amnt',\n",
       " u'term',\n",
       " u'emp_length',\n",
       " u'home_ownership',\n",
       " u'annual_inc',\n",
       " u'purpose',\n",
       " u'addr_state',\n",
       " u'dti',\n",
       " u'delinq_2yrs',\n",
       " u'revol_util',\n",
       " u'total_acc',\n",
       " u'longest_credit_length',\n",
       " u'verification_status']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of predictor columns\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O Grid Search (GBM)\n",
    "\n",
    "Now that we have prepared the data, we can train some models.  Rather than training models manually one-by-one, we will make use of the H2O Grid Search functionality train a bunch of models at once.\n",
    "\n",
    "H2O offers two types of grid search -- \"Cartesian\" and \"RandomDiscrete\".  Cartesian is the traditional, exhaustive, grid search over all the combinations of model parameters in the grid.  Random Grid Search will sample sets of model parameters randomly for some specified period of time (or maximum number of models).\n",
    "\n",
    "We will use GBM as an example to demonstrate H2O's grid search functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O Grid Search:\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "# Import H2O GBM:\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian Grid Search\n",
    "\n",
    "We first need to define a grid of GBM model hyperparameters.  For this particular example, we will grid over the following model parameters:\n",
    "\n",
    "- `learn_rate`\n",
    "- `max_depth`\n",
    "- `sample_rate`\n",
    "- `col_sample_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params1 = {'learn_rate': [0.01, 0.1], \n",
    "                'max_depth': [3, 5, 9],\n",
    "                'sample_rate': [0.8, 1.0],\n",
    "                'col_sample_rate': [0.2, 0.5, 1.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and validate a grid of GBMs\n",
    "\n",
    "If you want to specify non-default model parameters that are not part of your grid, you pass them along to the grid via the `H2OGridSearch.train()` method.  See `ntrees=100` in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Grid Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_grid1 = H2OGridSearch(model=H2OGradientBoostingEstimator,\n",
    "                          grid_id='gbm_grid1',\n",
    "                          hyper_params=gbm_params1)\n",
    "gbm_grid1.train(x=x, y=y, \n",
    "                training_frame=train, \n",
    "                validation_frame=valid, \n",
    "                ntrees=100,\n",
    "                seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare model performance\n",
    "\n",
    "To compare the model performance among all the models in a grid, sorted by a particular metric (e.g. AUC), you can use the `get_grid` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_gridperf1 = gbm_grid1.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sample_rate  max_depth  learn_rate  col_sample_rate           model_ids  \\\n",
      "0             0.8          5        0.10              0.5  gbm_grid1_model_20   \n",
      "1             1.0          5        0.10              0.5  gbm_grid1_model_21   \n",
      "2             1.0          5        0.10              1.0  gbm_grid1_model_33   \n",
      "3             0.8          5        0.10              1.0  gbm_grid1_model_32   \n",
      "4             1.0          5        0.10              0.2   gbm_grid1_model_9   \n",
      "5             0.8          5        0.10              0.2   gbm_grid1_model_8   \n",
      "6             1.0          9        0.10              0.2  gbm_grid1_model_11   \n",
      "7             1.0          3        0.10              1.0  gbm_grid1_model_31   \n",
      "8             0.8          3        0.10              1.0  gbm_grid1_model_30   \n",
      "9             0.8          3        0.10              0.5  gbm_grid1_model_18   \n",
      "10            0.8          9        0.10              0.2  gbm_grid1_model_10   \n",
      "11            1.0          3        0.10              0.5  gbm_grid1_model_19   \n",
      "12            0.8          9        0.10              1.0  gbm_grid1_model_34   \n",
      "13            0.8          9        0.01              0.2   gbm_grid1_model_4   \n",
      "14            1.0          9        0.10              1.0  gbm_grid1_model_35   \n",
      "15            1.0          3        0.10              0.2   gbm_grid1_model_7   \n",
      "16            1.0          9        0.10              0.5  gbm_grid1_model_23   \n",
      "17            1.0          9        0.01              0.2   gbm_grid1_model_5   \n",
      "18            0.8          9        0.10              0.5  gbm_grid1_model_22   \n",
      "19            0.8          3        0.10              0.2   gbm_grid1_model_6   \n",
      "20            0.8          9        0.01              0.5  gbm_grid1_model_16   \n",
      "21            1.0          9        0.01              0.5  gbm_grid1_model_17   \n",
      "22            0.8          9        0.01              1.0  gbm_grid1_model_28   \n",
      "23            1.0          5        0.01              0.2   gbm_grid1_model_3   \n",
      "24            0.8          5        0.01              0.2   gbm_grid1_model_2   \n",
      "25            0.8          5        0.01              0.5  gbm_grid1_model_14   \n",
      "26            1.0          5        0.01              0.5  gbm_grid1_model_15   \n",
      "27            1.0          9        0.01              1.0  gbm_grid1_model_29   \n",
      "28            0.8          5        0.01              1.0  gbm_grid1_model_26   \n",
      "29            0.8          3        0.01              0.2   gbm_grid1_model_0   \n",
      "30            1.0          5        0.01              1.0  gbm_grid1_model_27   \n",
      "31            1.0          3        0.01              0.2   gbm_grid1_model_1   \n",
      "32            0.8          3        0.01              0.5  gbm_grid1_model_12   \n",
      "33            1.0          3        0.01              0.5  gbm_grid1_model_13   \n",
      "34            0.8          3        0.01              1.0  gbm_grid1_model_24   \n",
      "35            1.0          3        0.01              1.0  gbm_grid1_model_25   \n",
      "\n",
      "         auc  \n",
      "0   0.683249  \n",
      "1   0.682177  \n",
      "2   0.681717  \n",
      "3   0.681631  \n",
      "4   0.680052  \n",
      "5   0.679570  \n",
      "6   0.679463  \n",
      "7   0.678786  \n",
      "8   0.678706  \n",
      "9   0.678384  \n",
      "10  0.678170  \n",
      "11  0.677944  \n",
      "12  0.677304  \n",
      "13  0.676602  \n",
      "14  0.675844  \n",
      "15  0.675524  \n",
      "16  0.675215  \n",
      "17  0.675132  \n",
      "18  0.674954  \n",
      "19  0.674663  \n",
      "20  0.673498  \n",
      "21  0.672061  \n",
      "22  0.670481  \n",
      "23  0.668157  \n",
      "24  0.667506  \n",
      "25  0.665893  \n",
      "26  0.665571  \n",
      "27  0.664203  \n",
      "28  0.663779  \n",
      "29  0.663458  \n",
      "30  0.662185  \n",
      "31  0.661913  \n",
      "32  0.656994  \n",
      "33  0.655723  \n",
      "34  0.654087  \n",
      "35  0.653352  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print gbm_gridperf1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Grid Search\n",
    "This example is set to run fairly quickly -- increase `max_runtime_secs` or `max_models` to cover more of the hyperparameter space.  Also, you can expand the hyperparameter space of each of the algorithms by modifying the hyper parameter list below.\n",
    "\n",
    "In addition to the hyperparameter dictionary, we will specify the `search_criteria` as 'RandomDiscrete', with a max numeber of models equal to 36. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params2 = {'learn_rate': [i * 0.01 for i in range(1, 11)], \n",
    "                'max_depth': list(range(2, 11)),\n",
    "                'sample_rate': [i * 0.1 for i in range(5, 11)],\n",
    "                'col_sample_rate': [i * 0.1 for i in range(1, 11)]}\n",
    "\n",
    "# Search criteria\n",
    "search_criteria2 = {'strategy': 'RandomDiscrete', 'max_models': 36}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and validate a random grid of GBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Grid Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_grid2 = H2OGridSearch(model=H2OGradientBoostingEstimator,\n",
    "                          grid_id='gbm_grid2',\n",
    "                          hyper_params=gbm_params2,\n",
    "                          search_criteria=search_criteria2)\n",
    "gbm_grid2.train(x=x, y=y, \n",
    "                training_frame=train, \n",
    "                validation_frame=valid, \n",
    "                ntrees=100,\n",
    "                seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_gridperf2 = gbm_grid2.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sample_rate  max_depth  learn_rate  col_sample_rate           model_ids  \\\n",
      "0             1.0          7        0.09              0.5  gbm_grid2_model_24   \n",
      "1             0.5          6        0.06              0.3  gbm_grid2_model_13   \n",
      "2             0.5          6        0.07              0.5  gbm_grid2_model_33   \n",
      "3             0.5          6        0.07              0.7  gbm_grid2_model_18   \n",
      "4             0.8          7        0.07              1.0   gbm_grid2_model_2   \n",
      "5             0.9          7        0.05              0.5  gbm_grid2_model_30   \n",
      "6             0.9          9        0.10              0.4  gbm_grid2_model_32   \n",
      "7             0.8          9        0.08              0.7  gbm_grid2_model_19   \n",
      "8             0.5          6        0.05              0.9  gbm_grid2_model_16   \n",
      "9             0.7         10        0.02              0.2   gbm_grid2_model_9   \n",
      "10            0.9          8        0.09              0.9   gbm_grid2_model_0   \n",
      "11            0.7          7        0.04              0.4  gbm_grid2_model_31   \n",
      "12            0.8          6        0.05              0.6   gbm_grid2_model_1   \n",
      "13            0.6          7        0.06              0.6  gbm_grid2_model_25   \n",
      "14            0.7          3        0.09              1.0  gbm_grid2_model_15   \n",
      "15            0.6          9        0.03              0.3  gbm_grid2_model_14   \n",
      "16            0.6          9        0.06              0.1  gbm_grid2_model_17   \n",
      "17            1.0          8        0.06              1.0  gbm_grid2_model_35   \n",
      "18            0.9          8        0.04              0.6  gbm_grid2_model_28   \n",
      "19            0.9          6        0.07              0.1  gbm_grid2_model_34   \n",
      "20            0.6          9        0.01              0.2  gbm_grid2_model_20   \n",
      "21            0.8          3        0.07              1.0   gbm_grid2_model_6   \n",
      "22            0.5          7        0.03              0.5   gbm_grid2_model_7   \n",
      "23            0.8         10        0.09              0.9   gbm_grid2_model_3   \n",
      "24            0.5          2        0.10              0.9  gbm_grid2_model_12   \n",
      "25            0.9          5        0.04              0.2  gbm_grid2_model_22   \n",
      "26            0.8          7        0.02              0.2   gbm_grid2_model_4   \n",
      "27            0.8          8        0.03              0.7  gbm_grid2_model_11   \n",
      "28            0.7         10        0.03              0.9  gbm_grid2_model_27   \n",
      "29            0.8         10        0.03              0.6  gbm_grid2_model_29   \n",
      "30            0.8         10        0.01              0.9   gbm_grid2_model_5   \n",
      "31            0.9          6        0.03              0.9  gbm_grid2_model_21   \n",
      "32            0.9          8        0.01              0.7   gbm_grid2_model_8   \n",
      "33            0.5          4        0.02              0.5  gbm_grid2_model_10   \n",
      "34            1.0          5        0.01              0.4  gbm_grid2_model_23   \n",
      "35            0.7          3        0.03              0.5  gbm_grid2_model_26   \n",
      "\n",
      "         auc  \n",
      "0   0.682264  \n",
      "1   0.681719  \n",
      "2   0.681569  \n",
      "3   0.679859  \n",
      "4   0.679143  \n",
      "5   0.679114  \n",
      "6   0.678991  \n",
      "7   0.678880  \n",
      "8   0.678673  \n",
      "9   0.678402  \n",
      "10  0.678224  \n",
      "11  0.677884  \n",
      "12  0.677736  \n",
      "13  0.677646  \n",
      "14  0.677509  \n",
      "15  0.677292  \n",
      "16  0.676668  \n",
      "17  0.676207  \n",
      "18  0.675518  \n",
      "19  0.675370  \n",
      "20  0.675322  \n",
      "21  0.674961  \n",
      "22  0.674760  \n",
      "23  0.674471  \n",
      "24  0.673844  \n",
      "25  0.673746  \n",
      "26  0.673439  \n",
      "27  0.672747  \n",
      "28  0.672548  \n",
      "29  0.672192  \n",
      "30  0.670593  \n",
      "31  0.670142  \n",
      "32  0.668586  \n",
      "33  0.666197  \n",
      "34  0.666003  \n",
      "35  0.662911  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print gbm_gridperf2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add models to existing grid\n",
    "It looks like `learn_rate=0.1` does well here, which was the biggest `learn_rate` in our previous search, so maybe we want to add some models to our grid search with a higher `learn_rate`.  We will create a new `hyper_params` and `search_criteria` objects.\n",
    "\n",
    "We can add models to the same grid, by re-using the same `model_id`. Let's add as many new models as we can train in 60 seconds by setting `max_runtime_secs=60` in `search_criteria`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBM hyperparameters\n",
    "gbm_params = {'learn_rate': [i * 0.01 for i in range(1, 31)],  #updated\n",
    "                'max_depth': list(range(2, 11)),\n",
    "                'sample_rate': [0.9, 0.95, 1.0],  #updated\n",
    "                'col_sample_rate': [i * 0.1 for i in range(1, 11)]}\n",
    "\n",
    "# Search criteria\n",
    "search_criteria = {'strategy': 'RandomDiscrete', 'max_runtime_secs': 60}  #updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Grid Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_grid = H2OGridSearch(model=H2OGradientBoostingEstimator,\n",
    "                         grid_id='gbm_grid2',\n",
    "                         hyper_params=gbm_params,\n",
    "                         search_criteria=search_criteria)\n",
    "gbm_grid.train(x=x, y=y, \n",
    "               training_frame=train, \n",
    "               validation_frame=valid, \n",
    "               ntrees=100,\n",
    "               seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_gridperf = gbm_grid.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sample_rate  max_depth  learn_rate  col_sample_rate           model_ids  \\\n",
      "0            0.95          3        0.22              0.4  gbm_grid2_model_36   \n",
      "1            1.00          7        0.09              0.5  gbm_grid2_model_24   \n",
      "2            0.95          3        0.18              0.6  gbm_grid2_model_43   \n",
      "3            0.50          6        0.06              0.3  gbm_grid2_model_13   \n",
      "4            0.50          6        0.07              0.5  gbm_grid2_model_33   \n",
      "5            0.50          6        0.07              0.7  gbm_grid2_model_18   \n",
      "6            0.80          7        0.07              1.0   gbm_grid2_model_2   \n",
      "7            0.90          7        0.05              0.5  gbm_grid2_model_30   \n",
      "8            0.90          9        0.10              0.4  gbm_grid2_model_32   \n",
      "9            0.80          9        0.08              0.7  gbm_grid2_model_19   \n",
      "10           0.50          6        0.05              0.9  gbm_grid2_model_16   \n",
      "11           0.70         10        0.02              0.2   gbm_grid2_model_9   \n",
      "12           0.90          8        0.09              0.9   gbm_grid2_model_0   \n",
      "13           0.70          7        0.04              0.4  gbm_grid2_model_31   \n",
      "14           1.00          9        0.03              0.2  gbm_grid2_model_39   \n",
      "15           0.80          6        0.05              0.6   gbm_grid2_model_1   \n",
      "16           0.60          7        0.06              0.6  gbm_grid2_model_25   \n",
      "17           0.95          7        0.24              0.2  gbm_grid2_model_42   \n",
      "18           0.70          3        0.09              1.0  gbm_grid2_model_15   \n",
      "19           0.60          9        0.03              0.3  gbm_grid2_model_14   \n",
      "20           0.60          9        0.06              0.1  gbm_grid2_model_17   \n",
      "21           1.00          8        0.18              0.3  gbm_grid2_model_41   \n",
      "22           1.00          8        0.06              1.0  gbm_grid2_model_35   \n",
      "23           0.90          8        0.04              0.6  gbm_grid2_model_28   \n",
      "24           0.90          6        0.07              0.1  gbm_grid2_model_34   \n",
      "25           0.60          9        0.01              0.2  gbm_grid2_model_20   \n",
      "26           0.80          3        0.07              1.0   gbm_grid2_model_6   \n",
      "27           0.50          7        0.03              0.5   gbm_grid2_model_7   \n",
      "28           0.80         10        0.09              0.9   gbm_grid2_model_3   \n",
      "29           0.50          2        0.10              0.9  gbm_grid2_model_12   \n",
      "30           0.90          5        0.04              0.2  gbm_grid2_model_22   \n",
      "31           0.80          7        0.02              0.2   gbm_grid2_model_4   \n",
      "32           1.00         10        0.13              0.9  gbm_grid2_model_44   \n",
      "33           1.00          5        0.04              0.9  gbm_grid2_model_37   \n",
      "34           0.80          8        0.03              0.7  gbm_grid2_model_11   \n",
      "35           0.70         10        0.03              0.9  gbm_grid2_model_27   \n",
      "36           0.80         10        0.03              0.6  gbm_grid2_model_29   \n",
      "37           0.80         10        0.01              0.9   gbm_grid2_model_5   \n",
      "38           0.90          6        0.03              0.9  gbm_grid2_model_21   \n",
      "39           0.90          3        0.09              0.1  gbm_grid2_model_40   \n",
      "40           0.90          8        0.01              0.7   gbm_grid2_model_8   \n",
      "41           0.50          4        0.02              0.5  gbm_grid2_model_10   \n",
      "42           1.00          5        0.01              0.4  gbm_grid2_model_23   \n",
      "43           1.00          5        0.07              0.8  gbm_grid2_model_45   \n",
      "44           1.00          8        0.27              0.9  gbm_grid2_model_38   \n",
      "45           0.70          3        0.03              0.5  gbm_grid2_model_26   \n",
      "\n",
      "         auc  \n",
      "0   0.682592  \n",
      "1   0.682264  \n",
      "2   0.682224  \n",
      "3   0.681719  \n",
      "4   0.681569  \n",
      "5   0.679859  \n",
      "6   0.679143  \n",
      "7   0.679114  \n",
      "8   0.678991  \n",
      "9   0.678880  \n",
      "10  0.678673  \n",
      "11  0.678402  \n",
      "12  0.678224  \n",
      "13  0.677884  \n",
      "14  0.677760  \n",
      "15  0.677736  \n",
      "16  0.677646  \n",
      "17  0.677616  \n",
      "18  0.677509  \n",
      "19  0.677292  \n",
      "20  0.676668  \n",
      "21  0.676530  \n",
      "22  0.676207  \n",
      "23  0.675518  \n",
      "24  0.675370  \n",
      "25  0.675322  \n",
      "26  0.674961  \n",
      "27  0.674760  \n",
      "28  0.674471  \n",
      "29  0.673844  \n",
      "30  0.673746  \n",
      "31  0.673439  \n",
      "32  0.673340  \n",
      "33  0.673261  \n",
      "34  0.672747  \n",
      "35  0.672548  \n",
      "36  0.672192  \n",
      "37  0.670593  \n",
      "38  0.670142  \n",
      "39  0.669240  \n",
      "40  0.668586  \n",
      "41  0.666197  \n",
      "42  0.666003  \n",
      "43  0.665587  \n",
      "44  0.665410  \n",
      "45  0.662911  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print gbm_gridperf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's extract the top model, as determined by validation AUC, from the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab the model_id for the top GBM model, chosen by validation AUC\n",
    "best_gbm_model = gbm_gridperf.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683855910541\n"
     ]
    }
   ],
   "source": [
    "# Now let's evaluate the model performance on a test set\n",
    "# so we get an honest estimate of top model performance\n",
    "\n",
    "gbm_perf = best_gbm_model.model_performance(test)\n",
    "print gbm_perf.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slighly higher than the AUC on the validation set of the top model, however, model performance evaluated on a held-out test set is a more honest estimate of performance.  The validation set was used to select the best model, but should not be used to also evaluate the best model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## H2O Grid Search (DL)\n",
    "\n",
    "Next we will explore some deep learning parameters in a random grid search.  We will execute the grid search for 120 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O DL:\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DL hyperparameters\n",
    "activation_opt = [\"Rectifier\", \"RectifierWithDropout\", \"Maxout\", \"MaxoutWithDropout\"]\n",
    "l1_opt = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "l2_opt = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "dl_params = {'activation': activation_opt, 'l1': l1_opt, 'l2': l2_opt}\n",
    "\n",
    "# Search criteria\n",
    "search_criteria = {'strategy': 'RandomDiscrete', 'max_runtime_secs': 120, 'seed':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Grid Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "dl_grid = H2OGridSearch(model=H2ODeepLearningEstimator,\n",
    "                        grid_id='dl_grid1',\n",
    "                        hyper_params=dl_params,\n",
    "                        search_criteria=search_criteria)\n",
    "\n",
    "dl_grid.train(x=x, y=y,\n",
    "              training_frame=train, \n",
    "              validation_frame=valid, \n",
    "              hidden=[10,10],\n",
    "              hyper_params=dl_params,\n",
    "              search_criteria=search_criteria)\n",
    "\n",
    "dl_gridperf = dl_grid.get_grid(sort_by='auc', decreasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683855910541\n"
     ]
    }
   ],
   "source": [
    "# Grab the model_id for the top GBM model, chosen by validation AUC\n",
    "best_dl_model = dl_gridperf.models[0]\n",
    "\n",
    "# Now let's evaluate the model performance on a test set\n",
    "# so we get an honest estimate of top model performance\n",
    "\n",
    "dl_perf = best_gbm_model.model_performance(test)\n",
    "print dl_perf.auc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
