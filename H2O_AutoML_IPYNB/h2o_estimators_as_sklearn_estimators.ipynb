{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O-3 integration with Scikit-Learn\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Most of the `H2O-3` estimators available in the `Python` client (module `h2o.estimators`) provide a rudimentary support for the `sklearn` standard API, especially the following methods:\n",
    "- `fit(X, y)`\n",
    "- `predict(X)`\n",
    "- `get_params()`\n",
    "- `set_params(**params)`\n",
    "- `transform(X)` and `fit_transform(X, y)` for the transformers defined in module `h2o.transforms`\n",
    "\n",
    "Those methods have several limitations however:\n",
    "- they accept only `H2OFrame`s for the `X` and `y` parameters.\n",
    "- due to the previous limitation, they can be used in a sklearn Pipeline only in combination with `H2O-3` transformers.\n",
    "- naming collisions: for example some estimators and transformers (e.g. `H2OPCA`, `H2OSVD`, `H2OAggregatorEstimator`, `H2OGeneralizedLowRankEstimator`, ...) authorize a `transform` constructor param, leading to collisions when used in a sklearn Pipeline, and finally raising errors.\n",
    "- `get_params` and `set_params` not behaving exactly as they should in a `sklearn` context.\n",
    "\n",
    "All those limitations were not providing a good experience to the user that wanted to combine the power of `H2O-3` with the flexibility of `sklearn`. \n",
    "\n",
    "That's why since release `3.28.0.1`, our Python client comes with a new `h2o.sklearn` module that we hope will fulfill most of your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `h2o.sklearn` module\n",
    "\n",
    "This new support leaves untouched the existing estimators and transformers for backwards compatibility.\n",
    "\n",
    "Instead, the new `h2o.sklearn` module provides a collection of wrappers auto-generated on top of the original estimators (`h2o.estimators`) and transformers (`h2o.transforms`), as well as on top of `H2OAutoML`.\n",
    "\n",
    "Those wrappers try to cover most of the use-cases you may encounter when willing to use `H2O-3` with `sklearn`:\n",
    "- use the same naming convention as `sklearn`, e.g.:\n",
    "  - `H2OGradientBoostingClassifier`, ..., `H2OAutoMLClassifier` for classifiers (on top of `H2OGradientBoostingEstimator`, ..., `H2OAutoML`) that will automatically ensure that the target is turned into categorical.\n",
    "  - `H2OGradientBoostingRegressor`, ..., `H2OAutoMLRegressor` for regressors (on top of `H2OGradientBoostingEstimator`, ..., `H2OAutoML`).\n",
    "  - `H2OGradientBoostingEstimator`, ..., `H2OAutoMLEstimator` for generic estimators (accepting an additional `estimator_type` param with value None, 'classifier' or 'regressor').\n",
    "- expose only a `sklearn` API: \n",
    "  - a constructor with all params as keyword arguments and available for auto-completion in a Python environment (in a Jupyter notebook for example).\n",
    "  - `get_params()`, `set_params(**params)` with the first returning all possible parameters, not only the ones that have been set (on the constructor or in any other way).\n",
    "  - `fit(X, y)`, `predict(X)`, `fit_predict(X, y)` for all estimators (+ H2OAutoML).\n",
    "  - `predict_proba(X)`, `predict_log_proba(X)` for estimators (classifiers) that support predictions probabilities.\n",
    "  - `transform(X)`, `fit_transform(X, y)`, `inverse_transform(X)` for all transformers, and also estimators supporting transformations (e.g. H2OPrincipalComponentAnalysisEstimator).\n",
    "  - `score(X, y)` for estimators, using, like in `sklearn`, `sklearn.metrics.accuracy_score` for classifiers, and `sklearn.metrics.r2_score` for regressors.\n",
    "- also expose an `estimator` property (since `3.28.0.2`; in `3.28.0.1` it is only available as the `_estimator` \"private\" property) which is a reference to the original `H2OEstimator` (or `H2OAutoML`) instance: this way, the user can still access properties and methods from the estimator that are not exposed directly by the wrapper.\n",
    "- data parameters `X` and `y` accept various kinds of data: `H2OFrame`, `numpy` arrays, `pandas.DataFrame`. The wrapper will try to return predictions or transformation in the same format as the input. Basic rules will be explained below, but first, this means that those wrappers can be chained with any kind of `sklearn` component in a `sklearn.pipeline.Pipeline`.\n",
    "- for quickstarters, the wrappers can also automatically handle the connection to the local backend (auto-start, auto-connect, auto-shutdown when the wrapper is GC-ed). Note that this automatic connection management is disabled if the user first created a connection using `h2o.init()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `h2o.sklearn` in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following examples should show you how easily you can now use `H2O-3` in combination with `Scikit-Learn`.\n",
    "They will also point at some (minor) drawbacks that may appear, especially when alternating too many `sklearn` components with `H2O` components in the same pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# requirements for this tutorial (enable and run this cell to install)\n",
    "!pip install numpy pandas\n",
    "!pip install http://h2o-release.s3.amazonaws.com/h2o/rel-yu/2/Python/h2o-3.28.0.2-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixing `sklearn` with `h2o.sklearn` components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're going to use `sklearn.preprocessing` module, we will use `numpy` arrays as input for this section, and we will verify that we effectively obtain `numpy` arrays in return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  # pandas >= 0.19.2 required\n",
    "train = pd.read_csv(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_train.csv\").values\n",
    "test = pd.read_csv(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "X_test = test[:,:-1]\n",
    "y_test = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.0, 2.2, 4.0, 1.0],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [7.6, 3.0, 6.6, 2.1],\n",
       "        [5.6, 3.0, 4.5, 1.5],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [6.2, 3.4, 5.4, 2.3]], dtype=object),\n",
       " array(['Iris-versicolor', 'Iris-setosa', 'Iris-virginica',\n",
       "        'Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "        'Iris-setosa', 'Iris-virginica', 'Iris-setosa', 'Iris-virginica'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10], y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from h2o.sklearn import H2OGradientBoostingClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "pipeline_mix = Pipeline([\n",
    "    (\"standardize\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=2, random_state=seed)),\n",
    "    (\"classifier\", H2OGradientBoostingClassifier(seed=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set nested parameters directly from the pipeline object, especially useful when using `sklearn` cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'learn_rate' in pipeline_mix.named_steps.classifier.get_params()\n",
    "\n",
    "pipeline_mix.set_params(classifier__learn_rate=0.01)\n",
    "\n",
    "assert pipeline_mix.named_steps.classifier.learn_rate == 0.01"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipeline_mix.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our pipeline is defined, we can train our model.\n",
    "\n",
    "Note that as we haven't initialized `H2O-3` yet (normally using the `h2o.init()` method), then it will be automatically started by the first H2O component encountered in the pipeline.\n",
    "\n",
    "Please also note the progress bars showing that the training `numpy` data are converted and uploaded to the `H2O` backend.\n",
    "If you're annoyed by those progress bars and want to hide them, you should simply initialized `H2O` using `h2o.init(show_progress=False)`. This can also be done directly in the `h2o.sklearn` wrapper, using for example `H2OGradientBoostingClassifier(seed=seed, init_connection_args=dict(show_progress=False))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_202\"; Java(TM) SE Runtime Environment (build 1.8.0_202-b08); Java HotSpot(TM) 64-Bit Server VM (build 25.202-b08, mixed mode)\n",
      "  Starting server from /Users/seb/.pyenv/versions/3.7.5/envs/ve37-h2o/lib/python3.7/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/8j/1spy0dnn4pj3f018plmmbf200000gn/T/tmptnc_f88_\n",
      "  JVM stdout: /var/folders/8j/1spy0dnn4pj3f018plmmbf200000gn/T/tmptnc_f88_/h2o_seb_started_from_python.out\n",
      "  JVM stderr: /var/folders/8j/1spy0dnn4pj3f018plmmbf200000gn/T/tmptnc_f88_/h2o_seb_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Prague</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>7 days, 22 hours and 32 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_seb_g4b5vf</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Europe/Prague\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.2\n",
       "H2O cluster version age:    7 days, 22 hours and 32 minutes\n",
       "H2O cluster name:           H2O_from_python_seb_g4b5vf\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=2,\n",
       "                     random_state=42, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('classifier',\n",
       "                 H2OGradientBoostingClassifier(balance_classes=None,\n",
       "                                               build_tree_one_node=None,\n",
       "                                               calibrate_model=None,\n",
       "                                               calibration_frame=None,\n",
       "                                               ca...\n",
       "                                               fold_column=None,\n",
       "                                               histogram_type=None,\n",
       "                                               huber_alpha=None,\n",
       "                                               ignore_const_cols=None,\n",
       "                                               ignored_columns=None,\n",
       "                                               keep_cross_validation_fold_assignment=None,\n",
       "                                               keep_cross_validation_models=None,\n",
       "                                               keep_cross_validation_predictions=None,\n",
       "                                               learn_rate=0.01,\n",
       "                                               learn_rate_annealing=None,\n",
       "                                               max_abs_leafnode_pred=None,\n",
       "                                               max_after_balance_size=None,\n",
       "                                               max_confusion_matrix_size=None, ...))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mix.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "preds = pipeline_mix.predict(X_test)\n",
    "\n",
    "assert isinstance(preds, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score (automatically calls `predict` on the estimator internally)\n",
    "pipeline_mix.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1580229230862_1\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17535.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.626666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               50.0                     150.0              17535.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        1.0        4.0    3.613333         2.0         6.0     4.626666  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsMultinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.18709890373026358\n",
      "RMSE: 0.43254930786011386\n",
      "LogLoss: 0.5659162612656915\n",
      "Mean Per-Class Error: 0.0664488017429194\n",
      "\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0 / 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>3 / 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4 / 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7 / 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iris-setosa  Iris-versicolor  Iris-virginica     Error     Rate\n",
       "0         30.0              0.0             0.0  0.000000   0 / 30\n",
       "1          0.0             31.0             3.0  0.088235   3 / 34\n",
       "2          0.0              4.0            32.0  0.111111   4 / 36\n",
       "3         30.0             35.0            35.0  0.070000  7 / 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>hit_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  hit_ratio\n",
       "0  1       0.93\n",
       "1  2       1.00\n",
       "2  3       1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:54</td>\n",
       "      <td>0.020 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.177 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660893</td>\n",
       "      <td>1.081448</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.218 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.655158</td>\n",
       "      <td>1.064701</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.238 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.649463</td>\n",
       "      <td>1.048357</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.254 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.643808</td>\n",
       "      <td>1.032400</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.266 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.638194</td>\n",
       "      <td>1.016816</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.278 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.632622</td>\n",
       "      <td>1.001594</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.291 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.627091</td>\n",
       "      <td>0.986719</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.305 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.621602</td>\n",
       "      <td>0.972180</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.321 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.616156</td>\n",
       "      <td>0.957967</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.337 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.944068</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.351 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.605394</td>\n",
       "      <td>0.930473</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.375 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.600079</td>\n",
       "      <td>0.917173</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.386 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.594809</td>\n",
       "      <td>0.904159</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.400 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>0.891421</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.409 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.584402</td>\n",
       "      <td>0.878951</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.417 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.579266</td>\n",
       "      <td>0.866742</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.425 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.574176</td>\n",
       "      <td>0.854786</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.437 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.569133</td>\n",
       "      <td>0.843074</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2020-01-28 17:33:55</td>\n",
       "      <td>0.449 sec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.564135</td>\n",
       "      <td>0.831602</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-01-28 17:33:54   0.020 sec              0.0       0.666667   \n",
       "1     2020-01-28 17:33:55   0.177 sec              1.0       0.660893   \n",
       "2     2020-01-28 17:33:55   0.218 sec              2.0       0.655158   \n",
       "3     2020-01-28 17:33:55   0.238 sec              3.0       0.649463   \n",
       "4     2020-01-28 17:33:55   0.254 sec              4.0       0.643808   \n",
       "5     2020-01-28 17:33:55   0.266 sec              5.0       0.638194   \n",
       "6     2020-01-28 17:33:55   0.278 sec              6.0       0.632622   \n",
       "7     2020-01-28 17:33:55   0.291 sec              7.0       0.627091   \n",
       "8     2020-01-28 17:33:55   0.305 sec              8.0       0.621602   \n",
       "9     2020-01-28 17:33:55   0.321 sec              9.0       0.616156   \n",
       "10    2020-01-28 17:33:55   0.337 sec             10.0       0.610753   \n",
       "11    2020-01-28 17:33:55   0.351 sec             11.0       0.605394   \n",
       "12    2020-01-28 17:33:55   0.375 sec             12.0       0.600079   \n",
       "13    2020-01-28 17:33:55   0.386 sec             13.0       0.594809   \n",
       "14    2020-01-28 17:33:55   0.400 sec             14.0       0.589583   \n",
       "15    2020-01-28 17:33:55   0.409 sec             15.0       0.584402   \n",
       "16    2020-01-28 17:33:55   0.417 sec             16.0       0.579266   \n",
       "17    2020-01-28 17:33:55   0.425 sec             17.0       0.574176   \n",
       "18    2020-01-28 17:33:55   0.437 sec             18.0       0.569133   \n",
       "19    2020-01-28 17:33:55   0.449 sec             19.0       0.564135   \n",
       "\n",
       "    training_logloss  training_classification_error  \n",
       "0           1.098612                           0.72  \n",
       "1           1.081448                           0.07  \n",
       "2           1.064701                           0.07  \n",
       "3           1.048357                           0.07  \n",
       "4           1.032400                           0.07  \n",
       "5           1.016816                           0.07  \n",
       "6           1.001594                           0.07  \n",
       "7           0.986719                           0.07  \n",
       "8           0.972180                           0.07  \n",
       "9           0.957967                           0.07  \n",
       "10          0.944068                           0.07  \n",
       "11          0.930473                           0.07  \n",
       "12          0.917173                           0.07  \n",
       "13          0.904159                           0.07  \n",
       "14          0.891421                           0.07  \n",
       "15          0.878951                           0.07  \n",
       "16          0.866742                           0.07  \n",
       "17          0.854786                           0.07  \n",
       "18          0.843074                           0.07  \n",
       "19          0.831602                           0.07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>1747.859619</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.980498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2</td>\n",
       "      <td>34.764946</td>\n",
       "      <td>0.01989</td>\n",
       "      <td>0.019502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable  relative_importance  scaled_importance  percentage\n",
       "0       C1          1747.859619            1.00000    0.980498\n",
       "1       C2            34.764946            0.01989    0.019502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_wrapper = pipeline_mix.named_steps.classifier\n",
    "gbm_wrapper.estimator  # use gbm_wrapper._estimator in 3.28.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using only `h2o.sklearn` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o import H2OFrame\n",
    "from h2o.sklearn import H2OScaler, H2OPCA, H2OGradientBoostingClassifier\n",
    "\n",
    "seed = 42\n",
    "\n",
    "pipeline_h2o = Pipeline([\n",
    "    (\"standardize\", H2OScaler()),\n",
    "    (\"pca\", H2OPCA(k=2, seed=seed)),\n",
    "    (\"classifier\", H2OGradientBoostingClassifier(learn_rate=0.05, seed=seed))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as we are using only `H2O` components, we will look at the behaviour of the pipeline when we feed it with  `H2OFrame`s, and then when we feed it with `numpy` arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with `H2OFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "X_train_h2o, y_train_h2o = H2OFrame(X_train), H2OFrame(y_train)\n",
    "X_test_h2o, y_test_h2o = H2OFrame(X_test), H2OFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 H2OScaler(center=True, data_conversion='auto', scale=True)),\n",
       "                ('pca',\n",
       "                 H2OPCA(compute_metrics=True, data_conversion='auto',\n",
       "                        ignore_const_cols=True, impute_missing=False, k=2,\n",
       "                        max_iterations=None, model_id=None,\n",
       "                        pca_impl='mtj_evd_symmmatrix', pca_method='GramSVD',\n",
       "                        seed=42, transform='NONE',\n",
       "                        use_all_factor_levels=False)),\n",
       "                ('c...\n",
       "                                               fold_column=None,\n",
       "                                               histogram_type=None,\n",
       "                                               huber_alpha=None,\n",
       "                                               ignore_const_cols=None,\n",
       "                                               ignored_columns=None,\n",
       "                                               keep_cross_validation_fold_assignment=None,\n",
       "                                               keep_cross_validation_models=None,\n",
       "                                               keep_cross_validation_predictions=None,\n",
       "                                               learn_rate=0.05,\n",
       "                                               learn_rate_annealing=None,\n",
       "                                               max_abs_leafnode_pred=None,\n",
       "                                               max_after_balance_size=None,\n",
       "                                               max_confusion_matrix_size=None, ...))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_h2o.fit(X_train_h2o, y_train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline_h2o.predict(X_test_h2o)\n",
    "\n",
    "assert isinstance(preds, H2OFrame)\n",
    "\n",
    "pipeline_h2o.score(X_test_h2o, y_test_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we may have expected, our `sklearn` pipeline with only `H2O` components not only accepts H2O frames as input data, but it also produce `H2OFrame` results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with `numpy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardize',\n",
       "                 H2OScaler(center=True, data_conversion='auto', scale=True)),\n",
       "                ('pca',\n",
       "                 H2OPCA(compute_metrics=True, data_conversion='auto',\n",
       "                        ignore_const_cols=True, impute_missing=False, k=2,\n",
       "                        max_iterations=None, model_id=None,\n",
       "                        pca_impl='mtj_evd_symmmatrix', pca_method='GramSVD',\n",
       "                        seed=42, transform='NONE',\n",
       "                        use_all_factor_levels=False)),\n",
       "                ('c...\n",
       "                                               fold_column=None,\n",
       "                                               histogram_type=None,\n",
       "                                               huber_alpha=None,\n",
       "                                               ignore_const_cols=None,\n",
       "                                               ignored_columns=None,\n",
       "                                               keep_cross_validation_fold_assignment=None,\n",
       "                                               keep_cross_validation_models=None,\n",
       "                                               keep_cross_validation_predictions=None,\n",
       "                                               learn_rate=0.05,\n",
       "                                               learn_rate_annealing=None,\n",
       "                                               max_abs_leafnode_pred=None,\n",
       "                                               max_after_balance_size=None,\n",
       "                                               max_confusion_matrix_size=None, ...))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_h2o.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipeline_h2o.predict(X_test)\n",
    "\n",
    "assert isinstance(preds, H2OFrame)\n",
    "\n",
    "pipeline_h2o.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this call to `predict`, we could have expected that the predictions will also be represented as a `numpy` array.\n",
    "\n",
    "However, the logic used by the `h2o.sklearn` wrappers to detect the data format doesn't allow correctly guess user expectations here.\n",
    "This logic is relatively simple: by default, for a given estimator wrapper, it returns objects of the same type as the input:\n",
    "- `numpy` in -> `numpy` out\n",
    "- `H2OFrame` in -> `H2OFrame` out\n",
    "- `pd.DataFrame` in -> `numpy` out : small exception, but this is also `sklearn`'s behaviour.\n",
    "\n",
    "It doesn't apply by default for transformer wrappers though, as we expect `H2O` transformers to be chained with other `H2O` transformers or estimators; therefore, the `transform` method doesn't convert the result back by default to avoid too many useless conversions in the pipeline.\n",
    "\n",
    "There is still a possibility to control the output format of a wrapper by setting its `data_conversion` param.\n",
    "This parameter accepts 3 possible values:\n",
    "- `'auto'` (default for estimators): the result will be of the same type as the input, as discussed above.\n",
    "- `True`: the result is always converted to a `numpy` array.\n",
    "- `False` (default for transformers): the result is not converted, and therefore returned as an `H2OFrame`.\n",
    "\n",
    "Here we have multiple `H2O` transformers before the estimator, so if we want to always obtain `numpy` arrays, we can slightly modify the pipeline as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "pca prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_h2o_to_numpy = Pipeline([\n",
    "    (\"standardize\", H2OScaler()),\n",
    "    (\"pca\", H2OPCA(k=2, seed=seed)),\n",
    "    (\"classifier\", H2OGradientBoostingClassifier(learn_rate=0.05, seed=seed, data_conversion=True))\n",
    "])\n",
    "pipeline_h2o_to_numpy.fit(X_train, y_train)\n",
    "\n",
    "preds = pipeline_h2o_to_numpy.predict(X_test)\n",
    "assert isinstance(preds, np.ndarray)\n",
    "\n",
    "pipeline_h2o_to_numpy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understand how those `H2O` wrappers work and how they combine with `sklearn` components, we can use them to enhance `H2O` with some unique `sklearn` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.2146287 , 0.79900289, 0.60141706]),\n",
       " 'score_time': array([0.21829629, 0.2278161 , 0.44310427]),\n",
       " 'test_score': array([0.98, 0.94, 0.96])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from h2o.sklearn import H2OGradientBoostingClassifier\n",
    "\n",
    "seed = 2020\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('polyfeat', PolynomialFeatures(degree=2)),\n",
    "    ('classifier', H2OGradientBoostingClassifier(seed=seed))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "cross_validate(pipeline, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future improvements\n",
    "\n",
    "### Model persistence and deployment\n",
    "\n",
    "For deployment or simple reuse, `Scikit Learn` pipelines are commonly persisted using [pickle](https://docs.python.org/3.8/library/pickle.html) or [joblib](https://joblib.readthedocs.io/en/latest/persistence.html).\n",
    "\n",
    "The current version of the `h2o.sklearn` module allows persistence of untrained configured pipelines (for reuse), but fails with persistence (actually during loading) of trained pipelines: this is because `H2O-3` actual model resides on the Java backend, and pickling an `H2O-3` estimator will pickle the Python client object tree, but will ignore most of the information stored on the backend.\n",
    "\n",
    "We plan to solve this soon, probably by automatically exporting the model to binary format when pickling the wrapper, and then re-importing this model when unpickling the wrapper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve37-h2o",
   "language": "python",
   "name": "ve37-h2o"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
