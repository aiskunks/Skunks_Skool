{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory H2O Machine Learning Tutorial\n",
    "\n",
    "Prepared for H2O Open Chicago 2016: http://open.h2o.ai/chicago.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install H2O\n",
    "\n",
    "The first step in this tutorial is to download and install the h2o Python module.  \n",
    "The latest version is always here: http://www.h2o.ai/download/h2o/py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the H2O Cluster\n",
    "\n",
    "Once the Python module is installed, we begin by starting up a local (on your laptop) H2O cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "No instance found at ip and port: localhost:54321. Trying to start local jar...\n",
      "\n",
      "\n",
      "JVM stdout: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmp2QMc58/h2o_me_started_from_python.out\n",
      "JVM stderr: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmpgB7EFj/h2o_me_started_from_python.err\n",
      "Using ice_root: /var/folders/2j/jg4sl53d5q53tc2_nzm9fz5h0000gn/T/tmp2jVpCf\n",
      "\n",
      "\n",
      "Java Version: java version \"1.8.0_45\"\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_45-b14)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: ......... Connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/site-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>1 seconds 34 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_me_tva596</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>7.11 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.10</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ---------------------------------\n",
       "H2O cluster uptime:             1 seconds 34 milliseconds\n",
       "H2O cluster version:            3.8.2.3\n",
       "H2O cluster name:               H2O_started_from_python_me_tva596\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  7.11 GB\n",
       "H2O cluster total cores:        8\n",
       "H2O cluster allowed cores:      8\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.10\n",
       "------------------------------  ---------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the H2O library and start up the H2O cluter locally on your machine\n",
    "import h2o\n",
    "\n",
    "# Number of threads, nthreads = -1, means use all cores on your machine\n",
    "# max_mem_size is the maximum memory (in GB) to allocate to H2O\n",
    "h2o.init(nthreads = -1, max_mem_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "### Import data\n",
    "Next we will import a cleaned up version of the Lending Club \"Bad Loans\" dataset. The purpose here is to predict whether a loan will be bad (i.e. not repaid to the lender). The response column, `bad_loan`, is 1 if the loan was bad, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [                                                  ] 00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h2o/h2o.py:316: UserWarning: ParseError at file nfs://Volumes/H2OTOUR/loan.csv  at byte offset 4194304; error = 'Unmatched quote char \"'\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "loan_csv = \"/Volumes/H2OTOUR/loan.csv\"  # modify this for your machine\n",
    "# Alternatively, you can import the data directly from a URL\n",
    "#loan_csv = \"https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv\"\n",
    "data = h2o.import_file(loan_csv)  # 163,987 rows x 15 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163987, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode response variable\n",
    "Since we want to train a binary classification model, we must ensure that the response is coded as a factor. If the response is 0/1, H2O will assume it's numeric, which means that H2O will train a regression model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bad_loan'] = data['bad_loan'].asfactor()  #encode the binary repsonse as a factor\n",
    "data['bad_loan'].levels()  #optional: after encoding, this shows the two factor levels, '0' and '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition data\n",
    "\n",
    "Next, we partition the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition data into 70%, 15%, 15% chunks\n",
    "# Setting a seed will guarantee reproducibility\n",
    "\n",
    "splits = data.split_frame(ratios=[0.7, 0.15], seed=1)  \n",
    "\n",
    "train = splits[0]\n",
    "valid = splits[1]\n",
    "test = splits[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `split_frame()` uses approximate splitting not exact splitting (for efficiency), so these are not exactly 70%, 15% and 15% of the total rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114908\n",
      "24498\n",
      "24581\n"
     ]
    }
   ],
   "source": [
    "print train.nrow\n",
    "print valid.nrow\n",
    "print test.nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify response and predictor variables\n",
    "In H2O, we use `y` to designate the response variable and `x` to designate the list of predictor columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 'bad_loan'\n",
    "x = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.remove(y)  #remove the response\n",
    "x.remove('int_rate')  #remove the interest rate column because it's correlated with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'loan_amnt',\n",
       " u'term',\n",
       " u'emp_length',\n",
       " u'home_ownership',\n",
       " u'annual_inc',\n",
       " u'purpose',\n",
       " u'addr_state',\n",
       " u'dti',\n",
       " u'delinq_2yrs',\n",
       " u'revol_util',\n",
       " u'total_acc',\n",
       " u'longest_credit_length',\n",
       " u'verification_status']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of predictor columns\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O Machine Learning\n",
    "\n",
    "Now that we have prepared the data, we can train some models. We will start by training a single model from each of the H2O supervised algos:\n",
    "\n",
    "- Generalized Linear Model (GLM)\n",
    "- Random Forest (RF)\n",
    "- Gradient Boosting Machine (RF)\n",
    "- Deep Learning (DL)\n",
    "- Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generalized Linear Model\n",
    "Let's start with a basic binomial Generalized Linear Model (GLM).  By default, H2O's GLM uses a regularized, elastic net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O GLM:\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default GLM\n",
    "We first create an object of class, `\"H2OGeneralizedLinearEstimator\"`.  This does not actually do any training, it just sets the model up for training by specifying model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the GLM estimator:\n",
    "# Similar to R's glm() and H2O's R GLM, H2O's GLM has the \"family\" argument\n",
    "\n",
    "glm_fit1 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_fit1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `glm_fit1` object is initialized, we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "glm_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a GLM with lambda search\n",
    "\n",
    "Next we will do some automatic tuning by passing in a validation frame and setting `lambda_search = True`.  Since we are training a GLM with regularization, we should try to find the right amount of regularization (to avoid overfitting).  The model parameter, `lambda`, controls the amount of regularization in a GLM model and we can find the optimal value for `lambda` automatically by setting `lambda_search = True` and passing in a validation frame (which is used to evaluate model performance using a particular value of lambda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "glm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "glm_fit2 = H2OGeneralizedLinearEstimator(family='binomial', model_id='glm_fit2', lambda_search=True)\n",
    "glm_fit2.train(x=x, y=y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance\n",
    "Let's compare the performance of the two GLMs that were just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_perf1 = glm_fit1.model_performance(test)\n",
    "glm_perf2 = glm_fit2.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.14215506685\n",
      "R^2: 0.0639172702162\n",
      "LogLoss: 0.451078449301\n",
      "Null degrees of freedom: 24580\n",
      "Residual degrees of freedom: 24529\n",
      "Null deviance: 23672.9222656\n",
      "Residual deviance: 22175.9187245\n",
      "AIC: 22279.9187245\n",
      "AUC: 0.677449084114\n",
      "Gini: 0.354898168228\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.193355175264: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>13646.0</td>\n",
       "<td>6345.0</td>\n",
       "<td>0.3174</td>\n",
       "<td> (6345.0/19991.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1939.0</td>\n",
       "<td>2651.0</td>\n",
       "<td>0.4224</td>\n",
       "<td> (1939.0/4590.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>15585.0</td>\n",
       "<td>8996.0</td>\n",
       "<td>0.337</td>\n",
       "<td> (8284.0/24581.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      13646  6345  0.3174   (6345.0/19991.0)\n",
       "1      1939   2651  0.4224   (1939.0/4590.0)\n",
       "Total  15585  8996  0.337    (8284.0/24581.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1933552</td>\n",
       "<td>0.3902547</td>\n",
       "<td>225.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1187713</td>\n",
       "<td>0.5566546</td>\n",
       "<td>306.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2776294</td>\n",
       "<td>0.3538608</td>\n",
       "<td>149.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4942391</td>\n",
       "<td>0.8144095</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7445071</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0025754</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7445071</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.1984005</td>\n",
       "<td>0.2106992</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1800948</td>\n",
       "<td>0.6279826</td>\n",
       "<td>238.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.193355     0.390255  225\n",
       "max f2                      0.118771     0.556655  306\n",
       "max f0point5                0.277629     0.353861  149\n",
       "max accuracy                0.494239     0.81441   32\n",
       "max precision               0.744507     1         0\n",
       "max recall                  0.00257537   1         398\n",
       "max specificity             0.744507     1         0\n",
       "max absolute_MCC            0.1984       0.210699  220\n",
       "max min_per_class_accuracy  0.180095     0.627983  238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 18.67 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100077</td>\n",
       "<td>0.4653731</td>\n",
       "<td>2.8735958</td>\n",
       "<td>2.8735958</td>\n",
       "<td>0.5365854</td>\n",
       "<td>0.5365854</td>\n",
       "<td>0.0287582</td>\n",
       "<td>0.0287582</td>\n",
       "<td>187.3595834</td>\n",
       "<td>187.3595834</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200155</td>\n",
       "<td>0.4286980</td>\n",
       "<td>2.3946632</td>\n",
       "<td>2.6341295</td>\n",
       "<td>0.4471545</td>\n",
       "<td>0.4918699</td>\n",
       "<td>0.0239651</td>\n",
       "<td>0.0527233</td>\n",
       "<td>139.4663195</td>\n",
       "<td>163.4129515</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300232</td>\n",
       "<td>0.4021176</td>\n",
       "<td>2.2422755</td>\n",
       "<td>2.5035115</td>\n",
       "<td>0.4186992</td>\n",
       "<td>0.4674797</td>\n",
       "<td>0.0224401</td>\n",
       "<td>0.0751634</td>\n",
       "<td>124.2275537</td>\n",
       "<td>150.3511522</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400309</td>\n",
       "<td>0.3854450</td>\n",
       "<td>2.2858149</td>\n",
       "<td>2.4490874</td>\n",
       "<td>0.4268293</td>\n",
       "<td>0.4573171</td>\n",
       "<td>0.0228758</td>\n",
       "<td>0.0980392</td>\n",
       "<td>128.5814868</td>\n",
       "<td>144.9087359</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500386</td>\n",
       "<td>0.3692889</td>\n",
       "<td>2.0463485</td>\n",
       "<td>2.3685396</td>\n",
       "<td>0.3821138</td>\n",
       "<td>0.4422764</td>\n",
       "<td>0.0204793</td>\n",
       "<td>0.1185185</td>\n",
       "<td>104.6348548</td>\n",
       "<td>136.8539597</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000366</td>\n",
       "<td>0.3097262</td>\n",
       "<td>1.8911445</td>\n",
       "<td>2.1299391</td>\n",
       "<td>0.3531326</td>\n",
       "<td>0.3977227</td>\n",
       "<td>0.0945534</td>\n",
       "<td>0.2130719</td>\n",
       "<td>89.1144473</td>\n",
       "<td>112.9939106</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500346</td>\n",
       "<td>0.2743849</td>\n",
       "<td>1.6863431</td>\n",
       "<td>1.9821139</td>\n",
       "<td>0.3148902</td>\n",
       "<td>0.3701193</td>\n",
       "<td>0.0843137</td>\n",
       "<td>0.2973856</td>\n",
       "<td>68.6343113</td>\n",
       "<td>98.2113869</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000325</td>\n",
       "<td>0.2482131</td>\n",
       "<td>1.3943922</td>\n",
       "<td>1.8352133</td>\n",
       "<td>0.2603743</td>\n",
       "<td>0.3426886</td>\n",
       "<td>0.0697168</td>\n",
       "<td>0.3671024</td>\n",
       "<td>39.4392238</td>\n",
       "<td>83.5213343</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000285</td>\n",
       "<td>0.2107834</td>\n",
       "<td>1.2789191</td>\n",
       "<td>1.6498071</td>\n",
       "<td>0.2388120</td>\n",
       "<td>0.3080678</td>\n",
       "<td>0.1278867</td>\n",
       "<td>0.4949891</td>\n",
       "<td>27.8919131</td>\n",
       "<td>64.9807082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000244</td>\n",
       "<td>0.1844510</td>\n",
       "<td>1.1547311</td>\n",
       "<td>1.5260507</td>\n",
       "<td>0.2156225</td>\n",
       "<td>0.2849588</td>\n",
       "<td>0.1154684</td>\n",
       "<td>0.6104575</td>\n",
       "<td>15.4731072</td>\n",
       "<td>52.6050667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000203</td>\n",
       "<td>0.1620932</td>\n",
       "<td>0.9150699</td>\n",
       "<td>1.4038645</td>\n",
       "<td>0.1708706</td>\n",
       "<td>0.2621430</td>\n",
       "<td>0.0915033</td>\n",
       "<td>0.7019608</td>\n",
       "<td>-8.4930094</td>\n",
       "<td>40.3864457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000163</td>\n",
       "<td>0.1426701</td>\n",
       "<td>0.8257417</td>\n",
       "<td>1.3075172</td>\n",
       "<td>0.1541904</td>\n",
       "<td>0.2441521</td>\n",
       "<td>0.0825708</td>\n",
       "<td>0.7845316</td>\n",
       "<td>-17.4258346</td>\n",
       "<td>30.7517189</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000122</td>\n",
       "<td>0.1243252</td>\n",
       "<td>0.7538433</td>\n",
       "<td>1.2284255</td>\n",
       "<td>0.1407648</td>\n",
       "<td>0.2293834</td>\n",
       "<td>0.0753813</td>\n",
       "<td>0.8599129</td>\n",
       "<td>-24.6156696</td>\n",
       "<td>22.8425517</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000081</td>\n",
       "<td>0.1054696</td>\n",
       "<td>0.5664718</td>\n",
       "<td>1.1456855</td>\n",
       "<td>0.1057771</td>\n",
       "<td>0.2139334</td>\n",
       "<td>0.0566449</td>\n",
       "<td>0.9165577</td>\n",
       "<td>-43.3528153</td>\n",
       "<td>14.5685516</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000041</td>\n",
       "<td>0.0829515</td>\n",
       "<td>0.5098247</td>\n",
       "<td>1.0750375</td>\n",
       "<td>0.0951993</td>\n",
       "<td>0.2007413</td>\n",
       "<td>0.0509804</td>\n",
       "<td>0.9675381</td>\n",
       "<td>-49.0175338</td>\n",
       "<td>7.5037503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3246319</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0606184</td>\n",
       "<td>0.1867296</td>\n",
       "<td>0.0324619</td>\n",
       "<td>1.0</td>\n",
       "<td>-67.5368057</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100077                   0.465373           2.8736    2.8736             0.536585         0.536585                    0.0287582       0.0287582                  187.36    187.36\n",
       "    2        0.0200155                   0.428698           2.39466   2.63413            0.447154         0.49187                     0.0239651       0.0527233                  139.466   163.413\n",
       "    3        0.0300232                   0.402118           2.24228   2.50351            0.418699         0.46748                     0.0224401       0.0751634                  124.228   150.351\n",
       "    4        0.0400309                   0.385445           2.28581   2.44909            0.426829         0.457317                    0.0228758       0.0980392                  128.581   144.909\n",
       "    5        0.0500386                   0.369289           2.04635   2.36854            0.382114         0.442276                    0.0204793       0.118519                   104.635   136.854\n",
       "    6        0.100037                    0.309726           1.89114   2.12994            0.353133         0.397723                    0.0945534       0.213072                   89.1144   112.994\n",
       "    7        0.150035                    0.274385           1.68634   1.98211            0.31489          0.370119                    0.0843137       0.297386                   68.6343   98.2114\n",
       "    8        0.200033                    0.248213           1.39439   1.83521            0.260374         0.342689                    0.0697168       0.367102                   39.4392   83.5213\n",
       "    9        0.300028                    0.210783           1.27892   1.64981            0.238812         0.308068                    0.127887        0.494989                   27.8919   64.9807\n",
       "    10       0.400024                    0.184451           1.15473   1.52605            0.215622         0.284959                    0.115468        0.610458                   15.4731   52.6051\n",
       "    11       0.50002                     0.162093           0.91507   1.40386            0.170871         0.262143                    0.0915033       0.701961                   -8.49301  40.3864\n",
       "    12       0.600016                    0.14267            0.825742  1.30752            0.15419          0.244152                    0.0825708       0.784532                   -17.4258  30.7517\n",
       "    13       0.700012                    0.124325           0.753843  1.22843            0.140765         0.229383                    0.0753813       0.859913                   -24.6157  22.8426\n",
       "    14       0.800008                    0.10547            0.566472  1.14569            0.105777         0.213933                    0.0566449       0.916558                   -43.3528  14.5686\n",
       "    15       0.900004                    0.0829515          0.509825  1.07504            0.0951993        0.200741                    0.0509804       0.967538                   -49.0175  7.50375\n",
       "    16       1                           3.3495e-16         0.324632  1                  0.0606184        0.18673                     0.0324619       1                          -67.5368  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.142127171974\n",
      "R^2: 0.0641009563279\n",
      "LogLoss: 0.450988500491\n",
      "Null degrees of freedom: 24580\n",
      "Residual degrees of freedom: 24517\n",
      "Null deviance: 23672.9222656\n",
      "Residual deviance: 22171.4966611\n",
      "AIC: 22299.4966611\n",
      "AUC: 0.677675858276\n",
      "Gini: 0.355351716551\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.192945688329: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>13596.0</td>\n",
       "<td>6395.0</td>\n",
       "<td>0.3199</td>\n",
       "<td> (6395.0/19991.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1928.0</td>\n",
       "<td>2662.0</td>\n",
       "<td>0.42</td>\n",
       "<td> (1928.0/4590.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>15524.0</td>\n",
       "<td>9057.0</td>\n",
       "<td>0.3386</td>\n",
       "<td> (8323.0/24581.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      13596  6395  0.3199   (6395.0/19991.0)\n",
       "1      1928   2662  0.42     (1928.0/4590.0)\n",
       "Total  15524  9057  0.3386   (8323.0/24581.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1929457</td>\n",
       "<td>0.3901224</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1189482</td>\n",
       "<td>0.5566554</td>\n",
       "<td>306.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2744616</td>\n",
       "<td>0.3542416</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4965808</td>\n",
       "<td>0.8144095</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7454046</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0027638</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7454046</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.1982820</td>\n",
       "<td>0.2105847</td>\n",
       "<td>215.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1802337</td>\n",
       "<td>0.6298475</td>\n",
       "<td>234.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.192946     0.390122  220\n",
       "max f2                      0.118948     0.556655  306\n",
       "max f0point5                0.274462     0.354242  146\n",
       "max accuracy                0.496581     0.81441   29\n",
       "max precision               0.745405     1         0\n",
       "max recall                  0.00276381   1         398\n",
       "max specificity             0.745405     1         0\n",
       "max absolute_MCC            0.198282     0.210585  215\n",
       "max min_per_class_accuracy  0.180234     0.629847  234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 18.67 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100077</td>\n",
       "<td>0.4655732</td>\n",
       "<td>2.8953655</td>\n",
       "<td>2.8953655</td>\n",
       "<td>0.5406504</td>\n",
       "<td>0.5406504</td>\n",
       "<td>0.0289760</td>\n",
       "<td>0.0289760</td>\n",
       "<td>189.5365499</td>\n",
       "<td>189.5365499</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200155</td>\n",
       "<td>0.4293011</td>\n",
       "<td>2.3946632</td>\n",
       "<td>2.6450143</td>\n",
       "<td>0.4471545</td>\n",
       "<td>0.4939024</td>\n",
       "<td>0.0239651</td>\n",
       "<td>0.0529412</td>\n",
       "<td>139.4663195</td>\n",
       "<td>164.5014347</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300232</td>\n",
       "<td>0.4025228</td>\n",
       "<td>2.2640452</td>\n",
       "<td>2.5180246</td>\n",
       "<td>0.4227642</td>\n",
       "<td>0.4701897</td>\n",
       "<td>0.0226580</td>\n",
       "<td>0.0755991</td>\n",
       "<td>126.4045203</td>\n",
       "<td>151.8024632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400309</td>\n",
       "<td>0.3850863</td>\n",
       "<td>2.2640452</td>\n",
       "<td>2.4545298</td>\n",
       "<td>0.4227642</td>\n",
       "<td>0.4583333</td>\n",
       "<td>0.0226580</td>\n",
       "<td>0.0982571</td>\n",
       "<td>126.4045203</td>\n",
       "<td>145.4529775</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500386</td>\n",
       "<td>0.3697433</td>\n",
       "<td>1.9592699</td>\n",
       "<td>2.3554778</td>\n",
       "<td>0.3658537</td>\n",
       "<td>0.4398374</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.1178649</td>\n",
       "<td>95.9269887</td>\n",
       "<td>135.5477797</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000366</td>\n",
       "<td>0.3099855</td>\n",
       "<td>1.9085744</td>\n",
       "<td>2.1321170</td>\n",
       "<td>0.3563873</td>\n",
       "<td>0.3981293</td>\n",
       "<td>0.0954248</td>\n",
       "<td>0.2132898</td>\n",
       "<td>90.8574376</td>\n",
       "<td>113.2116958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500346</td>\n",
       "<td>0.2745911</td>\n",
       "<td>1.6994155</td>\n",
       "<td>1.9879223</td>\n",
       "<td>0.3173312</td>\n",
       "<td>0.3712039</td>\n",
       "<td>0.0849673</td>\n",
       "<td>0.2982571</td>\n",
       "<td>69.9415541</td>\n",
       "<td>98.7922261</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000325</td>\n",
       "<td>0.2483325</td>\n",
       "<td>1.4118221</td>\n",
       "<td>1.8439265</td>\n",
       "<td>0.2636290</td>\n",
       "<td>0.3443156</td>\n",
       "<td>0.0705882</td>\n",
       "<td>0.3688453</td>\n",
       "<td>41.1822141</td>\n",
       "<td>84.3926522</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000285</td>\n",
       "<td>0.2108798</td>\n",
       "<td>1.2745617</td>\n",
       "<td>1.6541640</td>\n",
       "<td>0.2379984</td>\n",
       "<td>0.3088814</td>\n",
       "<td>0.1274510</td>\n",
       "<td>0.4962963</td>\n",
       "<td>27.4561655</td>\n",
       "<td>65.4163967</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000244</td>\n",
       "<td>0.1845418</td>\n",
       "<td>1.1525523</td>\n",
       "<td>1.5287738</td>\n",
       "<td>0.2152156</td>\n",
       "<td>0.2854673</td>\n",
       "<td>0.1152505</td>\n",
       "<td>0.6115468</td>\n",
       "<td>15.2552335</td>\n",
       "<td>52.8773812</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000203</td>\n",
       "<td>0.1620261</td>\n",
       "<td>0.9172486</td>\n",
       "<td>1.4064787</td>\n",
       "<td>0.1712775</td>\n",
       "<td>0.2626312</td>\n",
       "<td>0.0917211</td>\n",
       "<td>0.7032680</td>\n",
       "<td>-8.2751356</td>\n",
       "<td>40.6478730</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000163</td>\n",
       "<td>0.1427197</td>\n",
       "<td>0.8300991</td>\n",
       "<td>1.3104220</td>\n",
       "<td>0.1550041</td>\n",
       "<td>0.2446946</td>\n",
       "<td>0.0830065</td>\n",
       "<td>0.7862745</td>\n",
       "<td>-16.9900871</td>\n",
       "<td>31.0421976</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000122</td>\n",
       "<td>0.1242347</td>\n",
       "<td>0.7385921</td>\n",
       "<td>1.2287367</td>\n",
       "<td>0.1379170</td>\n",
       "<td>0.2294415</td>\n",
       "<td>0.0738562</td>\n",
       "<td>0.8601307</td>\n",
       "<td>-26.1407861</td>\n",
       "<td>22.8736747</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000081</td>\n",
       "<td>0.1054953</td>\n",
       "<td>0.5708293</td>\n",
       "<td>1.1465025</td>\n",
       "<td>0.1065907</td>\n",
       "<td>0.2140859</td>\n",
       "<td>0.0570806</td>\n",
       "<td>0.9172113</td>\n",
       "<td>-42.9170677</td>\n",
       "<td>14.6502501</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000041</td>\n",
       "<td>0.0829093</td>\n",
       "<td>0.5032884</td>\n",
       "<td>1.0750375</td>\n",
       "<td>0.0939788</td>\n",
       "<td>0.2007413</td>\n",
       "<td>0.0503268</td>\n",
       "<td>0.9675381</td>\n",
       "<td>-49.6711551</td>\n",
       "<td>7.5037503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3246319</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0606184</td>\n",
       "<td>0.1867296</td>\n",
       "<td>0.0324619</td>\n",
       "<td>1.0</td>\n",
       "<td>-67.5368057</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100077                   0.465573           2.89537   2.89537            0.54065          0.54065                     0.028976        0.028976                   189.537   189.537\n",
       "    2        0.0200155                   0.429301           2.39466   2.64501            0.447154         0.493902                    0.0239651       0.0529412                  139.466   164.501\n",
       "    3        0.0300232                   0.402523           2.26405   2.51802            0.422764         0.47019                     0.022658        0.0755991                  126.405   151.802\n",
       "    4        0.0400309                   0.385086           2.26405   2.45453            0.422764         0.458333                    0.022658        0.0982571                  126.405   145.453\n",
       "    5        0.0500386                   0.369743           1.95927   2.35548            0.365854         0.439837                    0.0196078       0.117865                   95.927    135.548\n",
       "    6        0.100037                    0.309986           1.90857   2.13212            0.356387         0.398129                    0.0954248       0.21329                    90.8574   113.212\n",
       "    7        0.150035                    0.274591           1.69942   1.98792            0.317331         0.371204                    0.0849673       0.298257                   69.9416   98.7922\n",
       "    8        0.200033                    0.248333           1.41182   1.84393            0.263629         0.344316                    0.0705882       0.368845                   41.1822   84.3927\n",
       "    9        0.300028                    0.21088            1.27456   1.65416            0.237998         0.308881                    0.127451        0.496296                   27.4562   65.4164\n",
       "    10       0.400024                    0.184542           1.15255   1.52877            0.215216         0.285467                    0.115251        0.611547                   15.2552   52.8774\n",
       "    11       0.50002                     0.162026           0.917249  1.40648            0.171277         0.262631                    0.0917211       0.703268                   -8.27514  40.6479\n",
       "    12       0.600016                    0.14272            0.830099  1.31042            0.155004         0.244695                    0.0830065       0.786275                   -16.9901  31.0422\n",
       "    13       0.700012                    0.124235           0.738592  1.22874            0.137917         0.229442                    0.0738562       0.860131                   -26.1408  22.8737\n",
       "    14       0.800008                    0.105495           0.570829  1.1465             0.106591         0.214086                    0.0570806       0.917211                   -42.9171  14.6503\n",
       "    15       0.900004                    0.0829093          0.503288  1.07504            0.0939788        0.200741                    0.0503268       0.967538                   -49.6712  7.50375\n",
       "    16       1                           3.25106e-16        0.324632  1                  0.0606184        0.18673                     0.0324619       1                          -67.5368  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print model performance\n",
    "print glm_perf1\n",
    "print glm_perf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of printing the entire model performance metrics object, it is probably easier to print just the metric that you are interested in comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677449084114\n",
      "0.677675858276\n"
     ]
    }
   ],
   "source": [
    "# Retreive test set AUC\n",
    "print glm_perf1.auc()\n",
    "print glm_perf2.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674306164325\n",
      "0.675512216705\n"
     ]
    }
   ],
   "source": [
    "# Compare test AUC to the training AUC and validation AUC\n",
    "print glm_fit2.auc(train=True)\n",
    "print glm_fit2.auc(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest\n",
    "H2O's Random Forest (RF) is implements a distributed version of the standard Random Forest algorithm and variable importance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O RF:\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default RF\n",
    "First we will train a basic Random Forest model with default parameters. Random Forest will infer the response distribution from the response encoding. A seed is required for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the RF estimator:\n",
    "\n",
    "rf_fit1 = H2ORandomForestEstimator(model_id='rf_fit1', seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `rf_fit1` object is initialized, we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drf Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an RF with more trees\n",
    "\n",
    "Next we will increase the number of trees used in the forest by setting `ntrees = 100`.  The default number of trees in an H2O Random Forest is 50, so this RF will be twice as big as the default.  Usually increasing the number of trees in an RF will increase performance as well.  Unlike Gradient Boosting Machines (GBMs), Random Forests are fairly resistant (although not free from) overfitting by increasing the number of trees.  See the GBM example below for additional guidance on preventing overfitting using H2O's early stopping functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drf Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit2 = H2ORandomForestEstimator(model_id='rf_fit2', ntrees=100, seed=1)\n",
    "rf_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model performance\n",
    "Let's compare the performance of the two RFs that were just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_perf1 = rf_fit1.model_performance(test)\n",
    "rf_perf2 = rf_fit2.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662266990734\n",
      "0.66525468051\n"
     ]
    }
   ],
   "source": [
    "# Retreive test set AUC\n",
    "print rf_perf1.auc()\n",
    "print rf_perf2.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validate performance\n",
    "\n",
    "Rather than using held-out test set to evaluate model performance, a user may wish to estimate model performance using cross-validation.  Using the RF algorithm (with default model parameters) as an example, we demonstrate how to perform k-fold cross-validation using H2O.  No custom code or loops are required, you simply specify the number of desired folds in the `nfolds` argument.\n",
    "\n",
    "Since we are not going to use a test set here, we can use the original (full) dataset, which we called `data` rather than the subsampled `train` dataset.  Note that this will take approximately k (`nfolds`) times longer than training a single RF model, since it will train k models in the cross-validation process (trained on n(k-1)/k rows), in addition to the final model trained on the full `training_frame` dataset with n rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drf Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "rf_fit3 = H2ORandomForestEstimator(model_id='rf_fit3', seed=1, nfolds=5)\n",
    "rf_fit3.train(x=x, y=y, training_frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the cross-validated AUC, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661201482614\n"
     ]
    }
   ],
   "source": [
    "print rf_fit3.auc(xval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cross-validated AUC is slighly higher than the test set performance we estimated for `rf_fit1`, and this is likely due to the fact that we trained on more data (n rows) than we did while using `train` as the training set (0.75*n rows) in `rf_fit1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Boosting Machine\n",
    "H2O's Gradient Boosting Machine (GBM) offers a Stochastic GBM, which can increase performance quite a bit compared to the original GBM implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import H2O GBM:\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default GBM\n",
    "\n",
    "First we will train a basic GBM model with default parameters. GBM will infer the response distribution from the response encoding if not specified explicitly through the `distribution` argument. A seed is required for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the GBM estimator:\n",
    "\n",
    "gbm_fit1 = H2OGradientBoostingEstimator(model_id='gbm_fit1', seed=1)\n",
    "gbm_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a GBM with more trees\n",
    "\n",
    "Next we will increase the number of trees used in the GBM by setting `ntrees=500`.  The default number of trees in an H2O GBM is 50, so this GBM will trained using ten times the default.  Increasing the number of trees in a GBM is one way to increase performance of the model, however, you have to be careful not to overfit your model to the training data by using too many trees.  To automatically find the optimal number of trees, you must use H2O's early stopping functionality.  This example will not do that, however, the following example will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_fit2 = H2OGradientBoostingEstimator(model_id='gbm_fit2', ntrees=500, seed=1)\n",
    "gbm_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a GBM with early stopping\n",
    "\n",
    "We will again set `ntrees = 500`, however, this time we will use early stopping in order to prevent overfitting (from too many trees).  All of H2O's algorithms have early stopping available, however, with the exception of Deep Learning, it is not enabled by default.  \n",
    "\n",
    "There are several parameters that should be used to control early stopping.  The three that are generic to all the algorithms are: `stopping_rounds`, `stopping_metric` and `stopping_tolerance`.  The stopping metric is the metric by which you'd like to measure performance, and so we will choose AUC here.  The `score_tree_interval` is a parameter specific to Random Forest and GBM.  Setting `score_tree_interval=5` will score the model after every five trees.  The parameters we have set below specify that the model will stop training after there have been three scoring intervals where the AUC has not increased more than 0.0005.  Since we have specified a validation frame, the stopping tolerance will be computed on validation AUC rather than training AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gbm Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Now let's use early stopping to find optimal ntrees\n",
    "\n",
    "gbm_fit3 = H2OGradientBoostingEstimator(model_id='gbm_fit3', \n",
    "                                        ntrees=500, \n",
    "                                        score_tree_interval=5,     #used for early stopping\n",
    "                                        stopping_rounds=3,         #used for early stopping\n",
    "                                        stopping_metric='AUC',     #used for early stopping\n",
    "                                        stopping_tolerance=0.0005, #used for early stopping\n",
    "                                        seed=1)\n",
    "\n",
    "# The use of a validation_frame is recommended with using early stopping\n",
    "gbm_fit3.train(x=x, y=y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model performance\n",
    "\n",
    "Let's compare the performance of the three GBMs that were just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_perf1 = gbm_fit1.model_performance(test)\n",
    "gbm_perf2 = gbm_fit2.model_performance(test)\n",
    "gbm_perf3 = gbm_fit3.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.682765594191\n",
      "0.671854616713\n",
      "0.68309902855\n"
     ]
    }
   ],
   "source": [
    "# Retreive test set AUC\n",
    "print gbm_perf1.auc()\n",
    "print gbm_perf2.auc()\n",
    "print gbm_perf3.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring History\n",
    "\n",
    "To examine the scoring history, use the `scoring_history` method on a trained model.  If `score_tree_interval` is not specified, it will score at various intervals, as we can see for `gbm_fit2.scoring_history()` below.  However, regular 5-tree intervals are used for `gbm_fit3.scoring_history()`.  \n",
    "\n",
    "The `gbm_fit2` was trained only using a training set (no validation set), so the scoring history is calculated for training set performance metrics only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_MSE</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_AUC</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:35</td>\n",
       "      <td>0.001 sec</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148714</td>\n",
       "      <td>0.474030</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:35</td>\n",
       "      <td>0.079 sec</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147252</td>\n",
       "      <td>0.469209</td>\n",
       "      <td>0.657210</td>\n",
       "      <td>2.680144</td>\n",
       "      <td>0.400599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:35</td>\n",
       "      <td>0.142 sec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.146021</td>\n",
       "      <td>0.465266</td>\n",
       "      <td>0.664849</td>\n",
       "      <td>2.663689</td>\n",
       "      <td>0.346703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.208 sec</td>\n",
       "      <td>3</td>\n",
       "      <td>0.144996</td>\n",
       "      <td>0.462036</td>\n",
       "      <td>0.667746</td>\n",
       "      <td>2.860431</td>\n",
       "      <td>0.339689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.288 sec</td>\n",
       "      <td>4</td>\n",
       "      <td>0.144123</td>\n",
       "      <td>0.459326</td>\n",
       "      <td>0.669405</td>\n",
       "      <td>2.900994</td>\n",
       "      <td>0.361158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.390 sec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.143373</td>\n",
       "      <td>0.456995</td>\n",
       "      <td>0.672514</td>\n",
       "      <td>3.013793</td>\n",
       "      <td>0.338366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.547 sec</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142734</td>\n",
       "      <td>0.455020</td>\n",
       "      <td>0.674697</td>\n",
       "      <td>3.080660</td>\n",
       "      <td>0.352987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.731 sec</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142280</td>\n",
       "      <td>0.453580</td>\n",
       "      <td>0.675089</td>\n",
       "      <td>3.088117</td>\n",
       "      <td>0.336130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:36</td>\n",
       "      <td>0.961 sec</td>\n",
       "      <td>8</td>\n",
       "      <td>0.141908</td>\n",
       "      <td>0.452386</td>\n",
       "      <td>0.675682</td>\n",
       "      <td>3.056254</td>\n",
       "      <td>0.341943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:37</td>\n",
       "      <td>1.195 sec</td>\n",
       "      <td>9</td>\n",
       "      <td>0.141588</td>\n",
       "      <td>0.451341</td>\n",
       "      <td>0.676213</td>\n",
       "      <td>3.064215</td>\n",
       "      <td>0.330917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:37</td>\n",
       "      <td>1.440 sec</td>\n",
       "      <td>10</td>\n",
       "      <td>0.141283</td>\n",
       "      <td>0.450355</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>3.071435</td>\n",
       "      <td>0.326792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:37</td>\n",
       "      <td>1.688 sec</td>\n",
       "      <td>11</td>\n",
       "      <td>0.141011</td>\n",
       "      <td>0.449475</td>\n",
       "      <td>0.678649</td>\n",
       "      <td>3.090803</td>\n",
       "      <td>0.338654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:37</td>\n",
       "      <td>1.946 sec</td>\n",
       "      <td>12</td>\n",
       "      <td>0.140687</td>\n",
       "      <td>0.448489</td>\n",
       "      <td>0.680646</td>\n",
       "      <td>3.129824</td>\n",
       "      <td>0.357338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:38</td>\n",
       "      <td>2.214 sec</td>\n",
       "      <td>13</td>\n",
       "      <td>0.140469</td>\n",
       "      <td>0.447748</td>\n",
       "      <td>0.681448</td>\n",
       "      <td>3.148167</td>\n",
       "      <td>0.326879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:38</td>\n",
       "      <td>2.497 sec</td>\n",
       "      <td>14</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.446905</td>\n",
       "      <td>0.683059</td>\n",
       "      <td>3.199288</td>\n",
       "      <td>0.339080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:38</td>\n",
       "      <td>2.792 sec</td>\n",
       "      <td>15</td>\n",
       "      <td>0.139958</td>\n",
       "      <td>0.446166</td>\n",
       "      <td>0.684262</td>\n",
       "      <td>3.202491</td>\n",
       "      <td>0.342204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:39</td>\n",
       "      <td>3.180 sec</td>\n",
       "      <td>16</td>\n",
       "      <td>0.139641</td>\n",
       "      <td>0.445185</td>\n",
       "      <td>0.686405</td>\n",
       "      <td>3.178202</td>\n",
       "      <td>0.346608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:39</td>\n",
       "      <td>3.507 sec</td>\n",
       "      <td>17</td>\n",
       "      <td>0.139408</td>\n",
       "      <td>0.444452</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>3.181708</td>\n",
       "      <td>0.337775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:39</td>\n",
       "      <td>3.822 sec</td>\n",
       "      <td>18</td>\n",
       "      <td>0.139165</td>\n",
       "      <td>0.443691</td>\n",
       "      <td>0.689043</td>\n",
       "      <td>3.219985</td>\n",
       "      <td>0.343675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:43</td>\n",
       "      <td>7.836 sec</td>\n",
       "      <td>114</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.420788</td>\n",
       "      <td>0.734584</td>\n",
       "      <td>4.119475</td>\n",
       "      <td>0.257040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:49:53</td>\n",
       "      <td>17.468 sec</td>\n",
       "      <td>324</td>\n",
       "      <td>0.125218</td>\n",
       "      <td>0.402242</td>\n",
       "      <td>0.770971</td>\n",
       "      <td>4.827585</td>\n",
       "      <td>0.244674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:02</td>\n",
       "      <td>26.971 sec</td>\n",
       "      <td>500</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>0.392608</td>\n",
       "      <td>0.788716</td>\n",
       "      <td>5.042888</td>\n",
       "      <td>0.212144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_MSE  \\\n",
       "0     2016-05-03 10:49:35   0.001 sec                0      0.148714   \n",
       "1     2016-05-03 10:49:35   0.079 sec                1      0.147252   \n",
       "2     2016-05-03 10:49:35   0.142 sec                2      0.146021   \n",
       "3     2016-05-03 10:49:36   0.208 sec                3      0.144996   \n",
       "4     2016-05-03 10:49:36   0.288 sec                4      0.144123   \n",
       "5     2016-05-03 10:49:36   0.390 sec                5      0.143373   \n",
       "6     2016-05-03 10:49:36   0.547 sec                6      0.142734   \n",
       "7     2016-05-03 10:49:36   0.731 sec                7      0.142280   \n",
       "8     2016-05-03 10:49:36   0.961 sec                8      0.141908   \n",
       "9     2016-05-03 10:49:37   1.195 sec                9      0.141588   \n",
       "10    2016-05-03 10:49:37   1.440 sec               10      0.141283   \n",
       "11    2016-05-03 10:49:37   1.688 sec               11      0.141011   \n",
       "12    2016-05-03 10:49:37   1.946 sec               12      0.140687   \n",
       "13    2016-05-03 10:49:38   2.214 sec               13      0.140469   \n",
       "14    2016-05-03 10:49:38   2.497 sec               14      0.140200   \n",
       "15    2016-05-03 10:49:38   2.792 sec               15      0.139958   \n",
       "16    2016-05-03 10:49:39   3.180 sec               16      0.139641   \n",
       "17    2016-05-03 10:49:39   3.507 sec               17      0.139408   \n",
       "18    2016-05-03 10:49:39   3.822 sec               18      0.139165   \n",
       "19    2016-05-03 10:49:43   7.836 sec              114      0.131661   \n",
       "20    2016-05-03 10:49:53  17.468 sec              324      0.125218   \n",
       "21    2016-05-03 10:50:02  26.971 sec              500      0.121869   \n",
       "\n",
       "    training_logloss  training_AUC  training_lift  \\\n",
       "0           0.474030      0.500000       1.000000   \n",
       "1           0.469209      0.657210       2.680144   \n",
       "2           0.465266      0.664849       2.663689   \n",
       "3           0.462036      0.667746       2.860431   \n",
       "4           0.459326      0.669405       2.900994   \n",
       "5           0.456995      0.672514       3.013793   \n",
       "6           0.455020      0.674697       3.080660   \n",
       "7           0.453580      0.675089       3.088117   \n",
       "8           0.452386      0.675682       3.056254   \n",
       "9           0.451341      0.676213       3.064215   \n",
       "10          0.450355      0.677305       3.071435   \n",
       "11          0.449475      0.678649       3.090803   \n",
       "12          0.448489      0.680646       3.129824   \n",
       "13          0.447748      0.681448       3.148167   \n",
       "14          0.446905      0.683059       3.199288   \n",
       "15          0.446166      0.684262       3.202491   \n",
       "16          0.445185      0.686405       3.178202   \n",
       "17          0.444452      0.687624       3.181708   \n",
       "18          0.443691      0.689043       3.219985   \n",
       "19          0.420788      0.734584       4.119475   \n",
       "20          0.402242      0.770971       4.827585   \n",
       "21          0.392608      0.788716       5.042888   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.818255  \n",
       "1                        0.400599  \n",
       "2                        0.346703  \n",
       "3                        0.339689  \n",
       "4                        0.361158  \n",
       "5                        0.338366  \n",
       "6                        0.352987  \n",
       "7                        0.336130  \n",
       "8                        0.341943  \n",
       "9                        0.330917  \n",
       "10                       0.326792  \n",
       "11                       0.338654  \n",
       "12                       0.357338  \n",
       "13                       0.326879  \n",
       "14                       0.339080  \n",
       "15                       0.342204  \n",
       "16                       0.346608  \n",
       "17                       0.337775  \n",
       "18                       0.343675  \n",
       "19                       0.257040  \n",
       "20                       0.244674  \n",
       "21                       0.212144  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_fit2.scoring_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When early stopping is used, we see that training stopped at 105 trees instead of the full 500.  Since we used a validation set in `gbm_fit3`, both training and validation performance metrics are stored in the scoring history object.  Take a look at the validation AUC to observe that the correct stopping tolerance was enforced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_MSE</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_AUC</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_MSE</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_AUC</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:06</td>\n",
       "      <td>0.001 sec</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148714</td>\n",
       "      <td>0.474030</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818255</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.479533</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:07</td>\n",
       "      <td>0.252 sec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.143373</td>\n",
       "      <td>0.456995</td>\n",
       "      <td>0.672514</td>\n",
       "      <td>3.013793</td>\n",
       "      <td>0.338366</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>0.464094</td>\n",
       "      <td>0.661129</td>\n",
       "      <td>2.618090</td>\n",
       "      <td>0.365377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:07</td>\n",
       "      <td>0.588 sec</td>\n",
       "      <td>10</td>\n",
       "      <td>0.141283</td>\n",
       "      <td>0.450355</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>3.071435</td>\n",
       "      <td>0.326792</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.458612</td>\n",
       "      <td>0.663678</td>\n",
       "      <td>2.729585</td>\n",
       "      <td>0.376765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:08</td>\n",
       "      <td>1.056 sec</td>\n",
       "      <td>15</td>\n",
       "      <td>0.139958</td>\n",
       "      <td>0.446166</td>\n",
       "      <td>0.684262</td>\n",
       "      <td>3.202491</td>\n",
       "      <td>0.342204</td>\n",
       "      <td>0.143614</td>\n",
       "      <td>0.455618</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>2.795897</td>\n",
       "      <td>0.365907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:08</td>\n",
       "      <td>1.584 sec</td>\n",
       "      <td>20</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>0.442520</td>\n",
       "      <td>0.691469</td>\n",
       "      <td>3.330029</td>\n",
       "      <td>0.347696</td>\n",
       "      <td>0.142869</td>\n",
       "      <td>0.453261</td>\n",
       "      <td>0.671361</td>\n",
       "      <td>2.927986</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:09</td>\n",
       "      <td>2.179 sec</td>\n",
       "      <td>25</td>\n",
       "      <td>0.137810</td>\n",
       "      <td>0.439517</td>\n",
       "      <td>0.697321</td>\n",
       "      <td>3.420935</td>\n",
       "      <td>0.301302</td>\n",
       "      <td>0.142248</td>\n",
       "      <td>0.451328</td>\n",
       "      <td>0.674848</td>\n",
       "      <td>2.861942</td>\n",
       "      <td>0.345130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:09</td>\n",
       "      <td>2.820 sec</td>\n",
       "      <td>30</td>\n",
       "      <td>0.137079</td>\n",
       "      <td>0.437235</td>\n",
       "      <td>0.701716</td>\n",
       "      <td>3.507056</td>\n",
       "      <td>0.304139</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.450176</td>\n",
       "      <td>0.676858</td>\n",
       "      <td>2.927986</td>\n",
       "      <td>0.359172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:10</td>\n",
       "      <td>3.522 sec</td>\n",
       "      <td>35</td>\n",
       "      <td>0.136501</td>\n",
       "      <td>0.435430</td>\n",
       "      <td>0.705013</td>\n",
       "      <td>3.502272</td>\n",
       "      <td>0.313198</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>0.449319</td>\n",
       "      <td>0.678392</td>\n",
       "      <td>2.972016</td>\n",
       "      <td>0.368520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:11</td>\n",
       "      <td>4.292 sec</td>\n",
       "      <td>40</td>\n",
       "      <td>0.135956</td>\n",
       "      <td>0.433766</td>\n",
       "      <td>0.708290</td>\n",
       "      <td>3.583609</td>\n",
       "      <td>0.309265</td>\n",
       "      <td>0.141474</td>\n",
       "      <td>0.448720</td>\n",
       "      <td>0.679649</td>\n",
       "      <td>2.905971</td>\n",
       "      <td>0.369214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:12</td>\n",
       "      <td>5.093 sec</td>\n",
       "      <td>45</td>\n",
       "      <td>0.135520</td>\n",
       "      <td>0.432420</td>\n",
       "      <td>0.710795</td>\n",
       "      <td>3.588393</td>\n",
       "      <td>0.301250</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.448253</td>\n",
       "      <td>0.680504</td>\n",
       "      <td>3.038061</td>\n",
       "      <td>0.355090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:12</td>\n",
       "      <td>5.976 sec</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135099</td>\n",
       "      <td>0.431123</td>\n",
       "      <td>0.713464</td>\n",
       "      <td>3.636238</td>\n",
       "      <td>0.307202</td>\n",
       "      <td>0.141164</td>\n",
       "      <td>0.447708</td>\n",
       "      <td>0.681717</td>\n",
       "      <td>3.016046</td>\n",
       "      <td>0.370928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:13</td>\n",
       "      <td>6.864 sec</td>\n",
       "      <td>55</td>\n",
       "      <td>0.134711</td>\n",
       "      <td>0.429942</td>\n",
       "      <td>0.715725</td>\n",
       "      <td>3.684084</td>\n",
       "      <td>0.298717</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.447464</td>\n",
       "      <td>0.682206</td>\n",
       "      <td>2.994031</td>\n",
       "      <td>0.362438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:16</td>\n",
       "      <td>9.652 sec</td>\n",
       "      <td>60</td>\n",
       "      <td>0.134390</td>\n",
       "      <td>0.428975</td>\n",
       "      <td>0.717671</td>\n",
       "      <td>3.746282</td>\n",
       "      <td>0.298656</td>\n",
       "      <td>0.141044</td>\n",
       "      <td>0.447256</td>\n",
       "      <td>0.682599</td>\n",
       "      <td>3.038061</td>\n",
       "      <td>0.369377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:17</td>\n",
       "      <td>10.690 sec</td>\n",
       "      <td>65</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>0.428143</td>\n",
       "      <td>0.719394</td>\n",
       "      <td>3.774989</td>\n",
       "      <td>0.296515</td>\n",
       "      <td>0.141015</td>\n",
       "      <td>0.447140</td>\n",
       "      <td>0.682809</td>\n",
       "      <td>3.038061</td>\n",
       "      <td>0.366683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:18</td>\n",
       "      <td>11.920 sec</td>\n",
       "      <td>70</td>\n",
       "      <td>0.133836</td>\n",
       "      <td>0.427330</td>\n",
       "      <td>0.720883</td>\n",
       "      <td>3.789343</td>\n",
       "      <td>0.304087</td>\n",
       "      <td>0.140991</td>\n",
       "      <td>0.447037</td>\n",
       "      <td>0.683032</td>\n",
       "      <td>3.060076</td>\n",
       "      <td>0.365050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:20</td>\n",
       "      <td>13.202 sec</td>\n",
       "      <td>75</td>\n",
       "      <td>0.133552</td>\n",
       "      <td>0.426443</td>\n",
       "      <td>0.722796</td>\n",
       "      <td>3.851542</td>\n",
       "      <td>0.306384</td>\n",
       "      <td>0.140982</td>\n",
       "      <td>0.446976</td>\n",
       "      <td>0.683183</td>\n",
       "      <td>3.016046</td>\n",
       "      <td>0.360233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:21</td>\n",
       "      <td>14.556 sec</td>\n",
       "      <td>80</td>\n",
       "      <td>0.133248</td>\n",
       "      <td>0.425563</td>\n",
       "      <td>0.724677</td>\n",
       "      <td>3.894603</td>\n",
       "      <td>0.294349</td>\n",
       "      <td>0.140996</td>\n",
       "      <td>0.447003</td>\n",
       "      <td>0.683057</td>\n",
       "      <td>3.016046</td>\n",
       "      <td>0.334354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:50:22</td>\n",
       "      <td>15.947 sec</td>\n",
       "      <td>85</td>\n",
       "      <td>0.133043</td>\n",
       "      <td>0.424940</td>\n",
       "      <td>0.725952</td>\n",
       "      <td>3.937663</td>\n",
       "      <td>0.298622</td>\n",
       "      <td>0.140997</td>\n",
       "      <td>0.446998</td>\n",
       "      <td>0.683126</td>\n",
       "      <td>3.016046</td>\n",
       "      <td>0.316189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_MSE  \\\n",
       "0     2016-05-03 10:50:06   0.001 sec                0      0.148714   \n",
       "1     2016-05-03 10:50:07   0.252 sec                5      0.143373   \n",
       "2     2016-05-03 10:50:07   0.588 sec               10      0.141283   \n",
       "3     2016-05-03 10:50:08   1.056 sec               15      0.139958   \n",
       "4     2016-05-03 10:50:08   1.584 sec               20      0.138783   \n",
       "5     2016-05-03 10:50:09   2.179 sec               25      0.137810   \n",
       "6     2016-05-03 10:50:09   2.820 sec               30      0.137079   \n",
       "7     2016-05-03 10:50:10   3.522 sec               35      0.136501   \n",
       "8     2016-05-03 10:50:11   4.292 sec               40      0.135956   \n",
       "9     2016-05-03 10:50:12   5.093 sec               45      0.135520   \n",
       "10    2016-05-03 10:50:12   5.976 sec               50      0.135099   \n",
       "11    2016-05-03 10:50:13   6.864 sec               55      0.134711   \n",
       "12    2016-05-03 10:50:16   9.652 sec               60      0.134390   \n",
       "13    2016-05-03 10:50:17  10.690 sec               65      0.134119   \n",
       "14    2016-05-03 10:50:18  11.920 sec               70      0.133836   \n",
       "15    2016-05-03 10:50:20  13.202 sec               75      0.133552   \n",
       "16    2016-05-03 10:50:21  14.556 sec               80      0.133248   \n",
       "17    2016-05-03 10:50:22  15.947 sec               85      0.133043   \n",
       "\n",
       "    training_logloss  training_AUC  training_lift  \\\n",
       "0           0.474030      0.500000       1.000000   \n",
       "1           0.456995      0.672514       3.013793   \n",
       "2           0.450355      0.677305       3.071435   \n",
       "3           0.446166      0.684262       3.202491   \n",
       "4           0.442520      0.691469       3.330029   \n",
       "5           0.439517      0.697321       3.420935   \n",
       "6           0.437235      0.701716       3.507056   \n",
       "7           0.435430      0.705013       3.502272   \n",
       "8           0.433766      0.708290       3.583609   \n",
       "9           0.432420      0.710795       3.588393   \n",
       "10          0.431123      0.713464       3.636238   \n",
       "11          0.429942      0.715725       3.684084   \n",
       "12          0.428975      0.717671       3.746282   \n",
       "13          0.428143      0.719394       3.774989   \n",
       "14          0.427330      0.720883       3.789343   \n",
       "15          0.426443      0.722796       3.851542   \n",
       "16          0.425563      0.724677       3.894603   \n",
       "17          0.424940      0.725952       3.937663   \n",
       "\n",
       "    training_classification_error  validation_MSE  validation_logloss  \\\n",
       "0                        0.818255        0.151042            0.479533   \n",
       "1                        0.338366        0.146227            0.464094   \n",
       "2                        0.326792        0.144531            0.458612   \n",
       "3                        0.342204        0.143614            0.455618   \n",
       "4                        0.347696        0.142869            0.453261   \n",
       "5                        0.301302        0.142248            0.451328   \n",
       "6                        0.304139        0.141892            0.450176   \n",
       "7                        0.313198        0.141634            0.449319   \n",
       "8                        0.309265        0.141474            0.448720   \n",
       "9                        0.301250        0.141333            0.448253   \n",
       "10                       0.307202        0.141164            0.447708   \n",
       "11                       0.298717        0.141100            0.447464   \n",
       "12                       0.298656        0.141044            0.447256   \n",
       "13                       0.296515        0.141015            0.447140   \n",
       "14                       0.304087        0.140991            0.447037   \n",
       "15                       0.306384        0.140982            0.446976   \n",
       "16                       0.294349        0.140996            0.447003   \n",
       "17                       0.298622        0.140997            0.446998   \n",
       "\n",
       "    validation_AUC  validation_lift  validation_classification_error  \n",
       "0         0.500000         1.000000                         0.814597  \n",
       "1         0.661129         2.618090                         0.365377  \n",
       "2         0.663678         2.729585                         0.376765  \n",
       "3         0.667416         2.795897                         0.365907  \n",
       "4         0.671361         2.927986                         0.348600  \n",
       "5         0.674848         2.861942                         0.345130  \n",
       "6         0.676858         2.927986                         0.359172  \n",
       "7         0.678392         2.972016                         0.368520  \n",
       "8         0.679649         2.905971                         0.369214  \n",
       "9         0.680504         3.038061                         0.355090  \n",
       "10        0.681717         3.016046                         0.370928  \n",
       "11        0.682206         2.994031                         0.362438  \n",
       "12        0.682599         3.038061                         0.369377  \n",
       "13        0.682809         3.038061                         0.366683  \n",
       "14        0.683032         3.060076                         0.365050  \n",
       "15        0.683183         3.016046                         0.360233  \n",
       "16        0.683057         3.016046                         0.334354  \n",
       "17        0.683126         3.016046                         0.316189  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_fit3.scoring_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep Learning\n",
    "\n",
    "H2O's Deep Learning algorithm is a multilayer feed-forward artificial neural network.  It can also be used to train an autoencoder, however, in the example below we will train a standard supervised prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O DL:\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default DL\n",
    "\n",
    "First we will train a basic DL model with default parameters. DL will infer the response distribution from the response encoding if not specified explicitly through the `distribution` argument.  H2O's DL will not be reproducbible if run on more than a single core, so in this example, the performance metrics below may vary slightly from what you see on your machine.\n",
    "\n",
    "In H2O's DL, early stopping is enabled by default, so below, it will use the training set and default stopping parameters to perform early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>16 minutes 43 seconds 380 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.3</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python_me_wzy124</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>7.03 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.10</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  --------------------------------------\n",
       "H2O cluster uptime:             16 minutes 43 seconds 380 milliseconds\n",
       "H2O cluster version:            3.8.2.3\n",
       "H2O cluster name:               H2O_started_from_python_me_wzy124\n",
       "H2O cluster total nodes:        1\n",
       "H2O cluster total free memory:  7.03 GB\n",
       "H2O cluster total cores:        8\n",
       "H2O cluster allowed cores:      8\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              127.0.0.1\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.10\n",
       "------------------------------  --------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the DL estimator:\n",
    "\n",
    "dl_fit1 = H2ODeepLearningEstimator(model_id='dl_fit1', seed=1)\n",
    "dl_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a DL with new architecture and more epochs\n",
    "\n",
    "Next we will increase the number of epochs used in the GBM by setting `epochs=20` (the default is 10).  Increasing the number of epochs in a deep neural net may increase performance of the model, however, you have to be careful not to overfit your model.  To automatically find the optimal number of epochs, you must use H2O's early stopping functionality.  Unlike the rest of the H2O algorithms, H2O's DL will use early by default, so we will first turn it off in the next example by setting `stopping_rounds=0`, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "dl_fit2 = H2ODeepLearningEstimator(model_id='dl_fit2', \n",
    "                                   epochs=20, \n",
    "                                   hidden=[10,10], \n",
    "                                   stopping_rounds=0,  #disable early stopping\n",
    "                                   seed=1)\n",
    "dl_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a DL with early stopping\n",
    "\n",
    "This example will use the same model parameters as `dl_fit2`, however, we will turn on early stopping and specify the stopping criterion.  We will also pass a validation set, as is recommended for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deeplearning Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "dl_fit3 = H2ODeepLearningEstimator(model_id='dl_fit3', \n",
    "                                   epochs=20, \n",
    "                                   hidden=[10,10],\n",
    "                                   score_interval=1,          #used for early stopping\n",
    "                                   stopping_rounds=3,         #used for early stopping\n",
    "                                   stopping_metric='AUC',     #used for early stopping\n",
    "                                   stopping_tolerance=0.0005, #used for early stopping\n",
    "                                   seed=1)\n",
    "dl_fit3.train(x=x, y=y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model performance\n",
    "\n",
    "Again, we will compare the model performance of the three models using a test set and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl_perf1 = dl_fit1.model_performance(test)\n",
    "dl_perf2 = dl_fit2.model_performance(test)\n",
    "dl_perf3 = dl_fit3.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679670061767\n",
      "0.675026229123\n",
      "0.681501550425\n"
     ]
    }
   ],
   "source": [
    "# Retreive test set AUC\n",
    "print dl_perf1.auc()\n",
    "print dl_perf2.auc()\n",
    "print dl_perf3.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_MSE</th>\n",
       "      <th>training_r2</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_AUC</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_MSE</th>\n",
       "      <th>validation_r2</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_AUC</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:34</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:35</td>\n",
       "      <td>0.288 sec</td>\n",
       "      <td>518093 rows/sec</td>\n",
       "      <td>0.870192</td>\n",
       "      <td>1</td>\n",
       "      <td>99992</td>\n",
       "      <td>0.143602</td>\n",
       "      <td>0.049866</td>\n",
       "      <td>0.457001</td>\n",
       "      <td>0.665048</td>\n",
       "      <td>2.558203</td>\n",
       "      <td>0.351841</td>\n",
       "      <td>0.143185</td>\n",
       "      <td>0.051933</td>\n",
       "      <td>0.455546</td>\n",
       "      <td>0.668156</td>\n",
       "      <td>2.663807</td>\n",
       "      <td>0.345743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:36</td>\n",
       "      <td>1.315 sec</td>\n",
       "      <td>607058 rows/sec</td>\n",
       "      <td>6.091290</td>\n",
       "      <td>7</td>\n",
       "      <td>699938</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.050810</td>\n",
       "      <td>0.456577</td>\n",
       "      <td>0.667244</td>\n",
       "      <td>2.721493</td>\n",
       "      <td>0.363875</td>\n",
       "      <td>0.142990</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.455240</td>\n",
       "      <td>0.671613</td>\n",
       "      <td>2.663807</td>\n",
       "      <td>0.358356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:37</td>\n",
       "      <td>2.338 sec</td>\n",
       "      <td>662289 rows/sec</td>\n",
       "      <td>12.184347</td>\n",
       "      <td>14</td>\n",
       "      <td>1400079</td>\n",
       "      <td>0.150780</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.486599</td>\n",
       "      <td>0.674257</td>\n",
       "      <td>2.667063</td>\n",
       "      <td>0.408879</td>\n",
       "      <td>0.150563</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.486139</td>\n",
       "      <td>0.677053</td>\n",
       "      <td>2.311568</td>\n",
       "      <td>0.363785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:38</td>\n",
       "      <td>3.433 sec</td>\n",
       "      <td>698969 rows/sec</td>\n",
       "      <td>19.148841</td>\n",
       "      <td>22</td>\n",
       "      <td>2200355</td>\n",
       "      <td>0.144177</td>\n",
       "      <td>0.046065</td>\n",
       "      <td>0.455084</td>\n",
       "      <td>0.676124</td>\n",
       "      <td>2.939212</td>\n",
       "      <td>0.344357</td>\n",
       "      <td>0.144628</td>\n",
       "      <td>0.042382</td>\n",
       "      <td>0.456287</td>\n",
       "      <td>0.676181</td>\n",
       "      <td>2.641792</td>\n",
       "      <td>0.357376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:38</td>\n",
       "      <td>3.638 sec</td>\n",
       "      <td>700242 rows/sec</td>\n",
       "      <td>20.018589</td>\n",
       "      <td>23</td>\n",
       "      <td>2300296</td>\n",
       "      <td>0.143916</td>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.460532</td>\n",
       "      <td>0.676903</td>\n",
       "      <td>3.048072</td>\n",
       "      <td>0.375607</td>\n",
       "      <td>0.144099</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.461880</td>\n",
       "      <td>0.675448</td>\n",
       "      <td>2.729852</td>\n",
       "      <td>0.340926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2016-05-03 10:51:38</td>\n",
       "      <td>3.710 sec</td>\n",
       "      <td>700029 rows/sec</td>\n",
       "      <td>20.018589</td>\n",
       "      <td>23</td>\n",
       "      <td>2300296</td>\n",
       "      <td>0.150780</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.486599</td>\n",
       "      <td>0.674257</td>\n",
       "      <td>2.667063</td>\n",
       "      <td>0.408879</td>\n",
       "      <td>0.150563</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.486139</td>\n",
       "      <td>0.677053</td>\n",
       "      <td>2.311568</td>\n",
       "      <td>0.363785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration   training_speed     epochs  iterations  \\\n",
       "0    2016-05-03 10:51:34   0.000 sec             None   0.000000           0   \n",
       "1    2016-05-03 10:51:35   0.288 sec  518093 rows/sec   0.870192           1   \n",
       "2    2016-05-03 10:51:36   1.315 sec  607058 rows/sec   6.091290           7   \n",
       "3    2016-05-03 10:51:37   2.338 sec  662289 rows/sec  12.184347          14   \n",
       "4    2016-05-03 10:51:38   3.433 sec  698969 rows/sec  19.148841          22   \n",
       "5    2016-05-03 10:51:38   3.638 sec  700242 rows/sec  20.018589          23   \n",
       "6    2016-05-03 10:51:38   3.710 sec  700029 rows/sec  20.018589          23   \n",
       "\n",
       "   samples  training_MSE  training_r2  training_logloss  training_AUC  \\\n",
       "0        0           NaN          NaN               NaN           NaN   \n",
       "1    99992      0.143602     0.049866          0.457001      0.665048   \n",
       "2   699938      0.143460     0.050810          0.456577      0.667244   \n",
       "3  1400079      0.150780     0.002375          0.486599      0.674257   \n",
       "4  2200355      0.144177     0.046065          0.455084      0.676124   \n",
       "5  2300296      0.143916     0.047794          0.460532      0.676903   \n",
       "6  2300296      0.150780     0.002375          0.486599      0.674257   \n",
       "\n",
       "   training_lift  training_classification_error  validation_MSE  \\\n",
       "0            NaN                            NaN             NaN   \n",
       "1       2.558203                       0.351841        0.143185   \n",
       "2       2.721493                       0.363875        0.142990   \n",
       "3       2.667063                       0.408879        0.150563   \n",
       "4       2.939212                       0.344357        0.144628   \n",
       "5       3.048072                       0.375607        0.144099   \n",
       "6       2.667063                       0.408879        0.150563   \n",
       "\n",
       "   validation_r2  validation_logloss  validation_AUC  validation_lift  \\\n",
       "0            NaN                 NaN             NaN              NaN   \n",
       "1       0.051933            0.455546        0.668156         2.663807   \n",
       "2       0.053225            0.455240        0.671613         2.663807   \n",
       "3       0.003085            0.486139        0.677053         2.311568   \n",
       "4       0.042382            0.456287        0.676181         2.641792   \n",
       "5       0.045880            0.461880        0.675448         2.729852   \n",
       "6       0.003085            0.486139        0.677053         2.311568   \n",
       "\n",
       "   validation_classification_error  \n",
       "0                              NaN  \n",
       "1                         0.345743  \n",
       "2                         0.358356  \n",
       "3                         0.363785  \n",
       "4                         0.357376  \n",
       "5                         0.340926  \n",
       "6                         0.363785  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_fit3.scoring_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Bayes\n",
    "\n",
    "The Naive Bayes (NB) algorithm does not usually beat an algorithm like a Random Forest or GBM, however it is still a popular algorithm, especially in the text domain (when your input is text encoded as \"Bag of Words\", for example).  The Naive Bayes algorithm is for binary or multiclass classification problems only, not regression.  Therefore, your response must be a factor instead of numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import H2O NB:\n",
    "from h2o.estimators.naive_bayes import H2ONaiveBayesEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default NB\n",
    "\n",
    "First we will train a basic NB model with default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the NB estimator:\n",
    "\n",
    "nb_fit1 = H2ONaiveBayesEstimator(model_id='nb_fit1')\n",
    "nb_fit1.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a NB model with Laplace Smoothing\n",
    "\n",
    "One of the few tunable model parameters for the Naive Bayes algorithm is the amount of Laplace smoothing.  The H2O Naive Bayes model will not use any Laplace smoothing by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "nb_fit2 = H2ONaiveBayesEstimator(model_id='nb_fit2', laplace=6)\n",
    "nb_fit2.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model performance\n",
    "\n",
    "We will compare the model performance of the two NB models using test set AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_perf1 = nb_fit1.model_performance(test)\n",
    "nb_perf2 = nb_fit2.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651356759779\n",
      "0.651421140603\n"
     ]
    }
   ],
   "source": [
    "# Retreive test set AUC\n",
    "print nb_perf1.auc()\n",
    "print nb_perf2.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
