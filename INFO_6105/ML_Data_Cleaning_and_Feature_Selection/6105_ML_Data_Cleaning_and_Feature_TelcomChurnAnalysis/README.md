# ML Data Cleaning and Feature Selection
This repository containts two files namely TelecomChurnAnalysis.ipynb and telecom_churn.csv.

The telecom_churn.ipynb is the python file containing the code and description of the exploratory data analysis done on the Telecom churn dataset present in the telecom_churn.csv file.

The telecom_churn.ipynb file contains a step wise detailed description of the methods and techniques used to understand the dataset along with all the processes implemented to clean the data and perform feature selection on it.
It will help you understand various aspects of the dataset and let you drive value from it.

Telecom Churn Dataset- https://www.kaggle.com/datasets/barun2104/telecom-churn?datasetId=567482&sortBy=voteCount

it will answer the below questions --

* What are the data types? (Only numeric and categorical)

* Are there missing values?

* What are the likely distributions of the numeric variables?

* Which independent variables are useful to predict a target (dependent variable)? (Use at least three methods)

* Which independent variables have missing data? How much? 

* Do the training and test sets have the same data?

* In the predictor variables independent of all the other predictor variables?

* Which predictor variables are the most important?

* Do the ranges of the predictor variables make sense?

* What are the distributions of the predictor variables?   

* Remove outliers and keep outliers (does if have an effect of the final predictive model)?

* Remove 1%, 5%, and 10% of your data randomly and impute the values back using at least 3 imputation methods. How well did the methods recover the missing values?  That is remove some data, check the % error on residuals for numeric data and check for bias and variance of the error.

For categorical data, calculate the accuracy and a confusion matrix.


